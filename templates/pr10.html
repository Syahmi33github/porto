{% extends "base_project.html" %}
<!-- sss -->
{% load static %}
<!-- sss -->
{% block navigation %}
<li><a href="#project-overview">Project Overview</a></li>
<li><a href="#import-data--module">Import Data Module</a></li>
<li><a href="#exploratory-data-analysis">Exploratory Data Analysis</a></li>
<li><a href="#data-pre-processing">Data Pre-Processing</a></li>
<li><a href="#modelling">Model Machine Learning</a></li>
<li><a href="#evaluation">Evaluation</a></li>
{% endblock navigation %}

<!--  -->
{% block contents %}
<section id="skimlit-nlp" class="cell-markdown" id="NNqaiyv7-76p">
  <h1>SkimLit NLP</h1>
</section>
<a href="https://www.linkedin.com/in/syahmi-sajid-907544243/">
  <div class="card-container">
    <div class="card cell-code">
      <img src="{% static 'img\sya.jpg' %}" alt="Gambar 1" />
      <div class="contentcard">
        <p>Aut : Syahmi Sajid</p>
      </div>
    </div>
  </div>
</a>
<img
  class="img-title"
  src="{% static 'img\skimlit\nlp.jpg' %}"
  class="img-responsive rounded"
  alt="Download free bootstrap 4 landing page, free boootstrap 4 templates, Download free bootstrap 4.1 landing page, free boootstrap 4.1.1 templates, meyawo Landing page"
/>
<section id="project-overview" class="cell-markdown" id="kH_XVtWc_FF7">
  <h2>Project Overview</h2>
</section>
<div class="cell-markdown" id="AlS8WoKV39mY">
  <p>
    <img
      src="{% static 'img\skimlit\8b1f70f54fa52ecb917f7de23131f0f4bc99f599.png' %}"
      alt="skimlit.png"
    />
  </p>
</div>
<div
  class="cell-code"
  data-execution_count="1"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="5a-wTOCJ3uaY"
  data-outputId="b2fb5b77-81d9-417e-902c-334004117f0c"
>
  <div class="sourceCode" id="cb1">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for GPU</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>nvidia<span class="op">-</span>smi <span class="op">-</span>L</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>GPU 0: Tesla T4 (UUID: GPU-16081a28-7889-3203-71f2-eac7c1445c00)
</code></pre>
  </div>
</div>
<section id="import-data--module" class="cell-markdown" id="GgengkGK6Sc4">
  <h2>IMPORT DATA &amp; MODULE</h2>
</section>
<div
  class="cell-code"
  data-execution_count="2"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="TQmMlI006V7G"
  data-outputId="9d890590-932e-4cd2-f8cb-6368f429929a"
>
  <div class="sourceCode" id="cb3">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>Franck<span class="op">-</span>Dernoncourt<span class="op">/</span>pubmed<span class="op">-</span>rct.git</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls pubmed<span class="op">-</span>rct</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Cloning into &#39;pubmed-rct&#39;...
remote: Enumerating objects: 33, done.ote: Counting objects: 100% (8/8), done.ote: Compressing objects: 100% (3/3), done.ote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25bers_replaced_with_at_sign
PubMed_20k_RCT
PubMed_20k_RCT_numbers_replaced_with_at_sign
README.md
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="3"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="hl4KliUl6cLX"
  data-outputId="187f4be6-98a2-4816-d3ab-5b98878db52d"
>
  <div class="sourceCode" id="cb5">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check what files are in the PubMed_20K dataset</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls pubmed<span class="op">-</span>rct<span class="op">/</span>PubMed_20k_RCT_numbers_replaced_with_at_sign</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>dev.txt  test.txt  train.txt
</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="4" id="72msS9nz6oD1">
  <div class="sourceCode" id="cb7">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Start by using the 20k dataset</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">&quot;pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/&quot;</span></span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="5"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="OCXp5MXo6ppG"
  data-outputId="5c357313-d5b2-4d8d-8cca-8d7fe57ea69a"
>
  <div class="sourceCode" id="cb8">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check all of the filenames in the target directory</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>filenames <span class="op">=</span> [data_dir <span class="op">+</span> filename <span class="cf">for</span> filename <span class="kw">in</span> os.listdir(data_dir)]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>filenames</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="5">
    <pre><code>[&#39;pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt&#39;,
 &#39;pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt&#39;,
 &#39;pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt&#39;]</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="6" id="dg846vPx6vQa">
  <div class="sourceCode" id="cb10">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create function to read the lines of a document</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_lines(filename):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">  Reads filename (a text file) and returns the lines of text as a list.</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">  Args:</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">      filename: a string containing the target filepath to read.</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">  Returns:</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">      A list of strings with one string per line from the target filename.</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">      For example:</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">      [&quot;this is the first line of filename&quot;,</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co">       &quot;this is the second line of filename&quot;,</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">       &quot;...&quot;]</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> <span class="bu">open</span>(filename, <span class="st">&quot;r&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> f.readlines()</span></code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="7" id="POujIRPVwLbm">
  <div class="sourceCode" id="cb11">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test = &quot;aaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaa aaaaaaaaaaa. bbbbbbbbbbbbbb bbbbbbbbbbbbbb bbbbbbbbb. ccccccccccccc cccccccccc.&quot;</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># get_lines(&quot;/content/test.txt&quot;)</span></span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="8"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="51Ay2i6m6yG9"
  data-outputId="1c18744d-2cc5-4f5f-d7f2-39147bd9e70a"
>
  <div class="sourceCode" id="cb12">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train_lines <span class="op">=</span> get_lines(data_dir<span class="op">+</span><span class="st">&quot;train.txt&quot;</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>train_lines[:<span class="dv">20</span>] <span class="co"># the whole first example of an abstract + a little more of the next one</span></span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="8">
    <pre><code>[&#39;###24293578\n&#39;,
 &#39;OBJECTIVE\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n&#39;,
 &#39;METHODS\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\n&#39;,
 &#39;METHODS\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\n&#39;,
 &#39;METHODS\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\n&#39;,
 &#39;METHODS\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\n&#39;,
 &#39;METHODS\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\n&#39;,
 &#39;RESULTS\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\n&#39;,
 &#39;RESULTS\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p &lt; @ ; @ ( @-@ @ ) , p &lt; @ ; @ ( @-@ @ ) , p &lt; @ ; and @ ( @-@ @ ) , p &lt; @ , respectively .\n&#39;,
 &#39;RESULTS\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\n&#39;,
 &#39;RESULTS\tThese differences remained significant at @ weeks .\n&#39;,
 &#39;RESULTS\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p &lt; @ ) .\n&#39;,
 &#39;CONCLUSIONS\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\n&#39;,
 &#39;\n&#39;,
 &#39;###24854809\n&#39;,
 &#39;BACKGROUND\tEmotional eating is associated with overeating and the development of obesity .\n&#39;,
 &#39;BACKGROUND\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\n&#39;,
 &#39;OBJECTIVE\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\n&#39;,
 &#39;OBJECTIVE\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\n&#39;,
 &#39;METHODS\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\n&#39;]</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="9" id="C-U5C9Nc7CtX">
  <div class="sourceCode" id="cb14">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_text_with_line_numbers(filename):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;&quot;&quot;Returns a list of dictionaries of abstract line data.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">  Takes in filename, reads its contents and sorts through each line,</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">  extracting things like the target label, the text of the sentence,</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">  how many sentences are in the current abstract and what sentence number</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">  the target line is.</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">  Args:</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">      filename: a string of the target text file to read and extract line data</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">      from.</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">  Returns:</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co">      A list of dictionaries each containing a line from an abstract,</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co">      the lines label, the lines position in the abstract and the total number</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co">      of lines in the abstract where the line is from. For example:</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co">      [{&quot;target&quot;: &#39;CONCLUSION&#39;,</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;text&quot;: The study couldn&#39;t have gone better, turns out people are kinder than you think&quot;,</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;line_number&quot;: 8,</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;total_lines&quot;: 8}]</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co">  &quot;&quot;&quot;</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  input_lines <span class="op">=</span> get_lines(filename) <span class="co"># get all lines from filename</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>  abstract_lines <span class="op">=</span> <span class="st">&quot;&quot;</span> <span class="co"># create an empty abstract</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>  abstract_samples <span class="op">=</span> [] <span class="co"># create an empty list of abstracts</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Loop through each line in target file</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> line <span class="kw">in</span> input_lines:</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> line.startswith(<span class="st">&quot;###&quot;</span>): <span class="co"># check to see if line is an ID line</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>      abstract_id <span class="op">=</span> line</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>      abstract_lines <span class="op">=</span> <span class="st">&quot;&quot;</span> <span class="co"># reset abstract string</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> line.isspace(): <span class="co"># check to see if line is a new line</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>      abstract_line_split <span class="op">=</span> abstract_lines.splitlines() <span class="co"># split abstract into separate lines</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Iterate through each line in abstract and count them at the same time</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> abstract_line_number, abstract_line <span class="kw">in</span> <span class="bu">enumerate</span>(abstract_line_split):</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>        line_data <span class="op">=</span> {} <span class="co"># create empty dict to store data from line</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>        target_text_split <span class="op">=</span> abstract_line.split(<span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>) <span class="co"># split target label from text</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        line_data[<span class="st">&quot;target&quot;</span>] <span class="op">=</span> target_text_split[<span class="dv">0</span>] <span class="co"># get target label</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>        line_data[<span class="st">&quot;text&quot;</span>] <span class="op">=</span> target_text_split[<span class="dv">1</span>].lower() <span class="co"># get target text and lower it</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>        line_data[<span class="st">&quot;line_number&quot;</span>] <span class="op">=</span> abstract_line_number <span class="co"># what number line does the line appear in the abstract?</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>        line_data[<span class="st">&quot;total_lines&quot;</span>] <span class="op">=</span> <span class="bu">len</span>(abstract_line_split) <span class="op">-</span> <span class="dv">1</span> <span class="co"># how many total lines are in the abstract? (start from 0)</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>        abstract_samples.append(line_data) <span class="co"># add line data to abstract samples list</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="co"># if the above conditions aren&#39;t fulfilled, the line contains a labelled sentence</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>      abstract_lines <span class="op">+=</span> line</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> abstract_samples</span></code></pre>
  </div>
</div>
<section id="exploratory-data-analysis" class="cell-markdown" id="kueSd3bs_d8d">
  <h2>EXPLORATORY DATA ANALYSIS</h2>
</section>
<div
  class="cell-code"
  data-execution_count="10"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="97TECW8kPyRv"
  data-outputId="1e598eed-e2b6-4f04-be6b-088d3c5234ba"
>
  <div class="sourceCode" id="cb15">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> <span class="st">&quot;sfsefesf </span><span class="ch">\n</span><span class="st"> aaaaaa </span><span class="ch">\n</span><span class="st"> sasa&quot;</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>split <span class="op">=</span> test.splitlines()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> abstract_line_number, abstract_line <span class="kw">in</span> <span class="bu">enumerate</span>(split):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(abstract_line_number)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(abstract_line)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>0
sfsefesf 
1
 aaaaaa 
2
 sasa
</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="11" id="w1_IBZogGImi">
  <div class="sourceCode" id="cb17">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a = preprocess_text_with_line_numbers(&quot;/content/a.txt&quot;)</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a</span></span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="12"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="B4eLwIep7FgS"
  data-outputId="75b4f767-8d0e-4ca5-d1f1-a6962ed528f7"
>
  <div class="sourceCode" id="cb18">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get data from file and preprocess it</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>train_samples <span class="op">=</span> preprocess_text_with_line_numbers(data_dir <span class="op">+</span> <span class="st">&quot;train.txt&quot;</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>val_samples <span class="op">=</span> preprocess_text_with_line_numbers(data_dir <span class="op">+</span> <span class="st">&quot;dev.txt&quot;</span>) <span class="co"># dev is another name for validation set</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>test_samples <span class="op">=</span> preprocess_text_with_line_numbers(data_dir <span class="op">+</span> <span class="st">&quot;test.txt&quot;</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(train_samples), <span class="bu">len</span>(val_samples), <span class="bu">len</span>(test_samples)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>CPU times: user 616 ms, sys: 105 ms, total: 721 ms
Wall time: 927 ms
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="12">
    <pre><code>(180040, 30212, 30135)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="13"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="k1Bqq1m27HM5"
  data-outputId="4e80429f-66bd-426a-df55-e462756b576a"
>
  <div class="sourceCode" id="cb21">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the first abstract of our training data</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>train_samples[:<span class="dv">14</span>]</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="13">
    <pre><code>[{&#39;target&#39;: &#39;OBJECTIVE&#39;,
  &#39;text&#39;: &#39;to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .&#39;,
  &#39;line_number&#39;: 0,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;METHODS&#39;,
  &#39;text&#39;: &#39;a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .&#39;,
  &#39;line_number&#39;: 1,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;METHODS&#39;,
  &#39;text&#39;: &#39;outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .&#39;,
  &#39;line_number&#39;: 2,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;METHODS&#39;,
  &#39;text&#39;: &#39;pain was assessed using the visual analog pain scale ( @-@ mm ) .&#39;,
  &#39;line_number&#39;: 3,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;METHODS&#39;,
  &#39;text&#39;: &#39;secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .&#39;,
  &#39;line_number&#39;: 4,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;METHODS&#39;,
  &#39;text&#39;: &#39;serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .&#39;,
  &#39;line_number&#39;: 5,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;RESULTS&#39;,
  &#39;text&#39;: &#39;there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .&#39;,
  &#39;line_number&#39;: 6,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;RESULTS&#39;,
  &#39;text&#39;: &#39;the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p &lt; @ ; @ ( @-@ @ ) , p &lt; @ ; @ ( @-@ @ ) , p &lt; @ ; and @ ( @-@ @ ) , p &lt; @ , respectively .&#39;,
  &#39;line_number&#39;: 7,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;RESULTS&#39;,
  &#39;text&#39;: &#39;further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .&#39;,
  &#39;line_number&#39;: 8,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;RESULTS&#39;,
  &#39;text&#39;: &#39;these differences remained significant at @ weeks .&#39;,
  &#39;line_number&#39;: 9,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;RESULTS&#39;,
  &#39;text&#39;: &#39;the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p &lt; @ ) .&#39;,
  &#39;line_number&#39;: 10,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;CONCLUSIONS&#39;,
  &#39;text&#39;: &#39;low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .&#39;,
  &#39;line_number&#39;: 11,
  &#39;total_lines&#39;: 11},
 {&#39;target&#39;: &#39;BACKGROUND&#39;,
  &#39;text&#39;: &#39;emotional eating is associated with overeating and the development of obesity .&#39;,
  &#39;line_number&#39;: 0,
  &#39;total_lines&#39;: 10},
 {&#39;target&#39;: &#39;BACKGROUND&#39;,
  &#39;text&#39;: &#39;yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .&#39;,
  &#39;line_number&#39;: 1,
  &#39;total_lines&#39;: 10}]</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="14"
  data-colab='{"base_uri":"https://localhost:8080/","height":488}'
  id="QIzYntjW7OTk"
  data-outputId="59cdbd2e-2393-4b95-a874-90d6e5675eda"
>
  <div class="sourceCode" id="cb23">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.DataFrame(train_samples)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>val_df <span class="op">=</span> pd.DataFrame(val_samples)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.DataFrame(test_samples)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>train_df.head(<span class="dv">14</span>)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="14">
    <div id="df-52603eb1-5dea-44d8-a12d-19270857a4f2">
      <div class="colab-df-container">
        <div>
          <style scoped>
            .dataframe tbody tr th:only-of-type {
              vertical-align: middle;
            }

            .dataframe tbody tr th {
              vertical-align: top;
            }

            .dataframe thead th {
              text-align: right;
            }
          </style>
          <table border="1" class="dataframe">
            <thead>
              <tr style="text-align: right">
                <th></th>
                <th>target</th>
                <th>text</th>
                <th>line_number</th>
                <th>total_lines</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th>0</th>
                <td>OBJECTIVE</td>
                <td>to investigate the efficacy of @ weeks of dail...</td>
                <td>0</td>
                <td>11</td>
              </tr>
              <tr>
                <th>1</th>
                <td>METHODS</td>
                <td>a total of @ patients with primary knee oa wer...</td>
                <td>1</td>
                <td>11</td>
              </tr>
              <tr>
                <th>2</th>
                <td>METHODS</td>
                <td>outcome measures included pain reduction and i...</td>
                <td>2</td>
                <td>11</td>
              </tr>
              <tr>
                <th>3</th>
                <td>METHODS</td>
                <td>pain was assessed using the visual analog pain...</td>
                <td>3</td>
                <td>11</td>
              </tr>
              <tr>
                <th>4</th>
                <td>METHODS</td>
                <td>secondary outcome measures included the wester...</td>
                <td>4</td>
                <td>11</td>
              </tr>
              <tr>
                <th>5</th>
                <td>METHODS</td>
                <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>
                <td>5</td>
                <td>11</td>
              </tr>
              <tr>
                <th>6</th>
                <td>RESULTS</td>
                <td>there was a clinically relevant reduction in t...</td>
                <td>6</td>
                <td>11</td>
              </tr>
              <tr>
                <th>7</th>
                <td>RESULTS</td>
                <td>the mean difference between treatment arms ( @...</td>
                <td>7</td>
                <td>11</td>
              </tr>
              <tr>
                <th>8</th>
                <td>RESULTS</td>
                <td>further , there was a clinically relevant redu...</td>
                <td>8</td>
                <td>11</td>
              </tr>
              <tr>
                <th>9</th>
                <td>RESULTS</td>
                <td>these differences remained significant at @ we...</td>
                <td>9</td>
                <td>11</td>
              </tr>
              <tr>
                <th>10</th>
                <td>RESULTS</td>
                <td>the outcome measures in rheumatology clinical ...</td>
                <td>10</td>
                <td>11</td>
              </tr>
              <tr>
                <th>11</th>
                <td>CONCLUSIONS</td>
                <td>low-dose oral prednisolone had both a short-te...</td>
                <td>11</td>
                <td>11</td>
              </tr>
              <tr>
                <th>12</th>
                <td>BACKGROUND</td>
                <td>emotional eating is associated with overeating...</td>
                <td>0</td>
                <td>10</td>
              </tr>
              <tr>
                <th>13</th>
                <td>BACKGROUND</td>
                <td>yet , empirical evidence for individual ( trai...</td>
                <td>1</td>
                <td>10</td>
              </tr>
            </tbody>
          </table>
        </div>
        <button
          class="colab-df-convert"
          onclick="convertToInteractive('df-52603eb1-5dea-44d8-a12d-19270857a4f2')"
          title="Convert this dataframe to an interactive table."
          style="display: none"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            height="24px"
            viewBox="0 0 24 24"
            width="24px"
          >
            <path d="M0 0h24v24H0V0z" fill="none" />
            <path
              d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"
            />
            <path
              d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"
            />
          </svg>
        </button>

        <div id="df-39561f64-ebfc-4f78-af1f-cbba880f42b4">
          <button
            class="colab-df-quickchart"
            onclick="quickchart('df-39561f64-ebfc-4f78-af1f-cbba880f42b4')"
            title="Suggest charts."
            style="display: none"
          >
            <svg
              xmlns="http://www.w3.org/2000/svg"
              height="24px"
              viewBox="0 0 24 24"
              width="24px"
            >
              <g>
                <path
                  d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"
                />
              </g>
            </svg>
          </button>
        </div>

        <style>
          .colab-df-quickchart {
            background-color: #e8f0fe;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            fill: #1967d2;
            height: 32px;
            padding: 0 0 0 0;
            width: 32px;
          }

          .colab-df-quickchart:hover {
            background-color: #e2ebfa;
            box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3),
              0px 1px 3px 1px rgba(60, 64, 67, 0.15);
            fill: #174ea6;
          }

          [theme="dark"] .colab-df-quickchart {
            background-color: #3b4455;
            fill: #d2e3fc;
          }

          [theme="dark"] .colab-df-quickchart:hover {
            background-color: #434b5c;
            box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
            filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
            fill: #ffffff;
          }
        </style>

        <script>
          async function quickchart(key) {
            const containerElement = document.querySelector("#" + key);
            const charts = await google.colab.kernel.invokeFunction(
              "suggestCharts",
              [key],
              {}
            );
          }
        </script>

        <script>
          function displayQuickchartButton(domScope) {
            let quickchartButtonEl = domScope.querySelector(
              "#df-39561f64-ebfc-4f78-af1f-cbba880f42b4 button.colab-df-quickchart"
            );
            quickchartButtonEl.style.display = google.colab.kernel.accessAllowed
              ? "block"
              : "none";
          }

          displayQuickchartButton(document);
        </script>
        <style>
          .colab-df-container {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
          }

          .colab-df-convert {
            background-color: #e8f0fe;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            fill: #1967d2;
            height: 32px;
            padding: 0 0 0 0;
            width: 32px;
          }

          .colab-df-convert:hover {
            background-color: #e2ebfa;
            box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3),
              0px 1px 3px 1px rgba(60, 64, 67, 0.15);
            fill: #174ea6;
          }

          [theme="dark"] .colab-df-convert {
            background-color: #3b4455;
            fill: #d2e3fc;
          }

          [theme="dark"] .colab-df-convert:hover {
            background-color: #434b5c;
            box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
            filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
            fill: #ffffff;
          }
        </style>

        <script>
          const buttonEl = document.querySelector(
            "#df-52603eb1-5dea-44d8-a12d-19270857a4f2 button.colab-df-convert"
          );
          buttonEl.style.display = google.colab.kernel.accessAllowed
            ? "block"
            : "none";

          async function convertToInteractive(key) {
            const element = document.querySelector(
              "#df-52603eb1-5dea-44d8-a12d-19270857a4f2"
            );
            const dataTable = await google.colab.kernel.invokeFunction(
              "convertToInteractive",
              [key],
              {}
            );
            if (!dataTable) return;

            const docLinkHtml =
              "Like what you see? Visit the " +
              '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>' +
              " to learn more about interactive tables.";
            element.innerHTML = "";
            dataTable["output_type"] = "display_data";
            await google.colab.output.renderOutput(dataTable, element);
            const docLink = document.createElement("div");
            docLink.innerHTML = docLinkHtml;
            element.appendChild(docLink);
          }
        </script>
      </div>
    </div>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="15"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="S5JtB55Q7hOx"
  data-outputId="449aa260-eaf9-40f1-c9c0-258c58577742"
>
  <div class="sourceCode" id="cb24">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution of labels in training data</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>train_df.target.value_counts()</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="15">
    <pre><code>METHODS        59353
RESULTS        57953
CONCLUSIONS    27168
BACKGROUND     21727
OBJECTIVE      13839
Name: target, dtype: int64</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="16"
  data-colab='{"base_uri":"https://localhost:8080/","height":431}'
  id="4N9DtqMfSMZS"
  data-outputId="77e8b2ee-0366-47ec-9c4f-56caeb291a02"
>
  <div class="sourceCode" id="cb26">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>train_df.total_lines.plot.hist()<span class="op">;</span></span></code></pre>
  </div>
  <div class="output display_data">
    <p>
      <img
        src="{% static 'img\skimlit\487ede329b7f4449b9fc416cbf3e7e217db8a4a1.png' %}"
      />
    </p>
  </div>
</div>
<section id="data-pre-processing" class="cell-markdown" id="XFpJW6ou_lZ0">
  <h2>Data Pre Processing</h2>
</section>
<section id="get-lists-of-sentences" class="cell-markdown" id="POuR1yweSTNs">
  <h3>Get lists of sentences</h3>
</section>
<div
  class="cell-code"
  data-execution_count="17"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="sF6Xl-8SSubO"
  data-outputId="f8900433-ba63-4e4c-bcec-1089955aec03"
>
  <div class="sourceCode" id="cb27">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert abstract text lines into lists</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>train_sentences <span class="op">=</span> train_df[<span class="st">&quot;text&quot;</span>].tolist()</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>val_sentences <span class="op">=</span> val_df[<span class="st">&quot;text&quot;</span>].tolist()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>test_sentences <span class="op">=</span> test_df[<span class="st">&quot;text&quot;</span>].tolist()</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(train_sentences), <span class="bu">len</span>(val_sentences), <span class="bu">len</span>(test_sentences)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="17">
    <pre><code>(180040, 30212, 30135)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="18"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="ttIbTeOqSzFA"
  data-outputId="df379082-ced3-4506-ed59-c085aefbee3c"
>
  <div class="sourceCode" id="cb29">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View first 10 lines of training sentences</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>train_sentences[:<span class="dv">10</span>]</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="18">
    <pre><code>[&#39;to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .&#39;,
 &#39;a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .&#39;,
 &#39;outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .&#39;,
 &#39;pain was assessed using the visual analog pain scale ( @-@ mm ) .&#39;,
 &#39;secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .&#39;,
 &#39;serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .&#39;,
 &#39;there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .&#39;,
 &#39;the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p &lt; @ ; @ ( @-@ @ ) , p &lt; @ ; @ ( @-@ @ ) , p &lt; @ ; and @ ( @-@ @ ) , p &lt; @ , respectively .&#39;,
 &#39;further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .&#39;,
 &#39;these differences remained significant at @ weeks .&#39;]</code></pre>
  </div>
</div>
<section
  id="make-numeric-labels-ml-models-require-numeric-labels"
  class="cell-markdown"
  id="JHXj3fTyTTb6"
>
  <h3>Make numeric labels (ML models require numeric labels)</h3>
</section>
<div
  class="cell-code"
  data-execution_count="19"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="RPtasPSyTSke"
  data-outputId="cc4b28ec-d041-42e0-9eed-57b238bcb03c"
>
  <div class="sourceCode" id="cb31">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># One hot encode labels</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>one_hot_encoder <span class="op">=</span> OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>train_labels_one_hot <span class="op">=</span> one_hot_encoder.fit_transform(train_df[<span class="st">&quot;target&quot;</span>].to_numpy().reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>val_labels_one_hot <span class="op">=</span> one_hot_encoder.transform(val_df[<span class="st">&quot;target&quot;</span>].to_numpy().reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>test_labels_one_hot <span class="op">=</span> one_hot_encoder.transform(test_df[<span class="st">&quot;target&quot;</span>].to_numpy().reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Check what training labels look like</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>train_labels_one_hot</span></code></pre>
  </div>
  <div class="output stream stderr">
    <pre><code>/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="19">
    <pre><code>array([[0., 0., 0., 1., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 1., 0., 0.],
       ...,
       [0., 0., 0., 0., 1.],
       [0., 1., 0., 0., 0.],
       [0., 1., 0., 0., 0.]])</code></pre>
  </div>
</div>
<section id="label-encode-labels" class="cell-markdown" id="4HS32ykxUb0z">
  <h3>Label encode labels</h3>
</section>
<div
  class="cell-code"
  data-execution_count="20"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="vy_ndHwCUc-O"
  data-outputId="b49b9ca0-81cc-452a-b462-ca83ce3a9404"
>
  <div class="sourceCode" id="cb34">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract labels (&quot;target&quot; columns) and encode them into integers</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>train_labels_encoded <span class="op">=</span> label_encoder.fit_transform(train_df[<span class="st">&quot;target&quot;</span>].to_numpy())</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>val_labels_encoded <span class="op">=</span> label_encoder.transform(val_df[<span class="st">&quot;target&quot;</span>].to_numpy())</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>test_labels_encoded <span class="op">=</span> label_encoder.transform(test_df[<span class="st">&quot;target&quot;</span>].to_numpy())</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Check what training labels look like</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>train_labels_encoded</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="20">
    <pre><code>array([3, 2, 2, ..., 4, 1, 1])</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="21"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="ZdkQ9EJcV7o9"
  data-outputId="aaaf2d89-b3f7-4cd4-e988-29f9bcf47aff"
>
  <div class="sourceCode" id="cb36">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get class names and number of classes from LabelEncoder instance</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(label_encoder.classes_)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> label_encoder.classes_</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>num_classes, class_names</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="21">
    <pre><code>(5,
 array([&#39;BACKGROUND&#39;, &#39;CONCLUSIONS&#39;, &#39;METHODS&#39;, &#39;OBJECTIVE&#39;, &#39;RESULTS&#39;],
       dtype=object))</code></pre>
  </div>
</div>
<section id="modelling" class="cell-markdown" id="MfO48LVq_stW">
  <h2>Modelling</h2>
</section>
<section
  id="model-0-getting-a-baseline"
  class="cell-markdown"
  id="SkdI79P-V_Ge"
>
  <h3>Model 0: Getting a baseline</h3>
</section>
<div class="cell-markdown" id="evN_TpgEWQ3K">
  <p>
    Our first model we'll be a TF-IDF Multinomial Naive Bayes as recommended by
    <a
      href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
      >Scikit-Learn's machine learning map.</a
    >
  </p>
  <p>
    To build it, we'll create a Scikit-Learn Pipeline which uses the
    TfidfVectorizer class to convert our abstract sentences to numbers using the
    TF-IDF (term frequency-inverse document frequecy) algorithm and then learns
    to classify our sentences using the MultinomialNB aglorithm.
  </p>
</div>
<div class="cell-code" data-execution_count="22" id="JlFIBW9lWdQz">
  <div class="sourceCode" id="cb38">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>model_0 <span class="op">=</span> Pipeline([</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  (<span class="st">&quot;tf-idf&quot;</span>, TfidfVectorizer()),</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  (<span class="st">&quot;clf&quot;</span>, MultinomialNB())</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the pipeline to the training data</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>model_0.fit(X<span class="op">=</span>train_sentences,</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>            y<span class="op">=</span>train_labels_encoded)<span class="op">;</span></span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="23"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="xFWa1ypKX97F"
  data-outputId="0e13c66e-8a6b-46e6-b30d-4f39273fd404"
>
  <div class="sourceCode" id="cb39">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate baseline on validation dataset</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>model_0.score(X<span class="op">=</span>val_sentences,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>              y<span class="op">=</span>val_labels_encoded)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="23">
    <pre><code>0.7218323844829869</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="24"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="pz5tUp0EX_-L"
  data-outputId="082f1887-fb80-47f3-d269-fb9208b0beb4"
>
  <div class="sourceCode" id="cb41">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>baseline_preds <span class="op">=</span> model_0.predict(val_sentences)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>baseline_preds</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="24">
    <pre><code>array([4, 1, 3, ..., 4, 4, 1])</code></pre>
  </div>
</div>
<section
  id="download-helper-functions-script"
  class="cell-markdown"
  id="UKwoOeVzYJVp"
>
  <h4>Download helper functions script</h4>
</section>
<div
  class="cell-code"
  data-execution_count="25"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="ELGZ4SJlYLFK"
  data-outputId="38add301-ad76-4769-8557-562d93f56c4d"
>
  <div class="sourceCode" id="cb43">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download helper functions script</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>raw.githubusercontent.com<span class="op">/</span>mrdbourke<span class="op">/</span>tensorflow<span class="op">-</span>deep<span class="op">-</span>learning<span class="op">/</span>main<span class="op">/</span>extras<span class="op">/</span>helper_functions.py</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>--2023-07-12 12:09:17--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 10246 (10K) [text/plain]
Saving to: ‘helper_functions.py’


helper_functions.py   0%[                    ]       0  --.-KB/s               
helper_functions.py 100%[===================&gt;]  10.01K  --.-KB/s    in 0s      

2023-07-12 12:09:17 (90.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]

</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="26" id="cOs990oyYRew">
  <div class="sourceCode" id="cb45">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import calculate_results helper function</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> helper_functions <span class="im">import</span> calculate_results</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="27"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="CBu59JYGYS9U"
  data-outputId="10f52b93-950e-46dc-be9b-b95d059cc2d8"
>
  <div class="sourceCode" id="cb46">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate baseline results</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>baseline_results <span class="op">=</span> calculate_results(y_true<span class="op">=</span>val_labels_encoded,</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>                                     y_pred<span class="op">=</span>baseline_preds)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>baseline_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="27">
    <pre><code>{&#39;accuracy&#39;: 72.1832384482987,
 &#39;precision&#39;: 0.7186466952323352,
 &#39;recall&#39;: 0.7218323844829869,
 &#39;f1&#39;: 0.6989250353450294}</code></pre>
  </div>
</div>
<section
  id="preparing-our-data-for-deep-sequence-models"
  class="cell-markdown"
  id="uADeWa6l-c2W"
>
  <h4>Preparing our data for deep sequence models</h4>
</section>
<div class="cell-code" data-execution_count="28" id="6Ui8fJk1__f_">
  <div class="sourceCode" id="cb48">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="29"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="Nmx2dWkJYoVA"
  data-outputId="2061ccf4-dd4a-4c49-ce88-77c5ce5f1896"
>
  <div class="sourceCode" id="cb49">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How long is each sentence on average?</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>sent_lens <span class="op">=</span> [<span class="bu">len</span>(sentence.split()) <span class="cf">for</span> sentence <span class="kw">in</span> train_sentences]</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>avg_sent_len <span class="op">=</span> np.mean(sent_lens)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>avg_sent_len <span class="co"># return average sentence length (in tokens)</span></span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="29">
    <pre><code>26.338269273494777</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="30"
  data-colab='{"base_uri":"https://localhost:8080/","height":430}'
  id="t0_Q822BBhyV"
  data-outputId="a790f4cd-3d11-4576-a820-5be1f8494b3f"
>
  <div class="sourceCode" id="cb51">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What&#39;s the distribution look like?</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>plt.hist(sent_lens, bins<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span></code></pre>
  </div>
  <div class="output display_data">
    <p>
      <img
        src="{% static 'img\skimlit\b92e5b881f059eff3c1f9f93b90aa5ed72c6febd.png' %}"
      />
    </p>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="31"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="PtVcRB6bCGk2"
  data-outputId="a2e8966c-2e42-4418-f368-0c07ce348ea5"
>
  <div class="sourceCode" id="cb52">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How long of a sentence covers 95% of the lengths?</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>output_seq_len <span class="op">=</span> <span class="bu">int</span>(np.percentile(sent_lens, <span class="dv">95</span>))</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>output_seq_len</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="31">
    <pre><code>55</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="32"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="AhQNnoFmCmPs"
  data-outputId="4d1df44a-827b-4d49-a8ea-e3d6b8006214"
>
  <div class="sourceCode" id="cb54">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Maximum sentence length in the training set</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="bu">max</span>(sent_lens)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="32">
    <pre><code>296</code></pre>
  </div>
</div>
<section id="create-text-vectorizer" class="cell-markdown" id="T9WPZ6taCozk">
  <h4>Create text vectorizer</h4>
</section>
<div class="cell-code" data-execution_count="33" id="gWNJb9pXCH1-">
  <div class="sourceCode" id="cb56">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>max_tokens <span class="op">=</span> <span class="dv">68000</span></span></code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="34" id="z2YytIXrDcUZ">
  <div class="sourceCode" id="cb57">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create text vectorizer</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers.experimental.preprocessing <span class="im">import</span> TextVectorization</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>text_vectorizer <span class="op">=</span> TextVectorization(max_tokens<span class="op">=</span>max_tokens, <span class="co"># number of words in vocabulary</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>                                    output_sequence_length<span class="op">=</span><span class="dv">55</span>) <span class="co"># desired output length of vectorized sequences</span></span></code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="35" id="S5GmK6pNDje0">
  <div class="sourceCode" id="cb58">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Adapt text vectorizer to training sentences</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>text_vectorizer.adapt(train_sentences)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="36"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="3YlgBvDJDkDd"
  data-outputId="98ceba05-1e20-4c97-fce7-b24d10314984"
>
  <div class="sourceCode" id="cb59">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out text vectorizer</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>target_sentence <span class="op">=</span> random.choice(train_sentences)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Text:</span><span class="ch">\n</span><span class="sc">{</span>target_sentence<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Length of text: </span><span class="sc">{</span><span class="bu">len</span>(target_sentence.split())<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Vectorized text:</span><span class="ch">\n</span><span class="sc">{</span>text_vectorizer([target_sentence])<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Text:
in this prospective , randomized trial , @ patients scheduled for laparoscopic cholecystectomy were assigned to propofol , isoflurane , desflurane , or sevoflurane for the maintenance of anesthesia .

Length of text: 30

Vectorized text:
[[   5   23  241   29   32   12 1141   11  723 2758    9  123    6  914
  4643 4123   16 1818   11    2  627    4  435    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0]]
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="37"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="-qDjOUbBGT7L"
  data-outputId="24db4bf9-1395-4ee4-a370-1848404b1eaa"
>
  <div class="sourceCode" id="cb61">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many words in our training vocabulary?</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>rct_20k_text_vocab <span class="op">=</span> text_vectorizer.get_vocabulary()</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of words in vocabulary: </span><span class="sc">{</span><span class="bu">len</span>(rct_20k_text_vocab)<span class="sc">}</span><span class="ss">&quot;</span>),</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Most common words in the vocabulary: </span><span class="sc">{</span>rct_20k_text_vocab[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Least common words in the vocabulary: </span><span class="sc">{</span>rct_20k_text_vocab[<span class="op">-</span><span class="dv">5</span>:]<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Number of words in vocabulary: 64841
Most common words in the vocabulary: [&#39;&#39;, &#39;[UNK]&#39;, &#39;the&#39;, &#39;and&#39;, &#39;of&#39;]
Least common words in the vocabulary: [&#39;aainduced&#39;, &#39;aaigroup&#39;, &#39;aachener&#39;, &#39;aachen&#39;, &#39;aaacp&#39;]
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="38"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="2kgbf8lPFzFu"
  data-outputId="bf2adf35-94c9-47a0-c64c-e75cff05693c"
>
  <div class="sourceCode" id="cb63">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the config of our text vectorizer</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>text_vectorizer.get_config()</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="38">
    <pre><code>{&#39;name&#39;: &#39;text_vectorization&#39;,
 &#39;trainable&#39;: True,
 &#39;dtype&#39;: &#39;string&#39;,
 &#39;batch_input_shape&#39;: (None,),
 &#39;max_tokens&#39;: 68000,
 &#39;standardize&#39;: &#39;lower_and_strip_punctuation&#39;,
 &#39;split&#39;: &#39;whitespace&#39;,
 &#39;ngrams&#39;: None,
 &#39;output_mode&#39;: &#39;int&#39;,
 &#39;output_sequence_length&#39;: 55,
 &#39;pad_to_max_tokens&#39;: False,
 &#39;sparse&#39;: False,
 &#39;ragged&#39;: False,
 &#39;vocabulary&#39;: None,
 &#39;idf_weights&#39;: None,
 &#39;encoding&#39;: &#39;utf-8&#39;,
 &#39;vocabulary_size&#39;: 64841}</code></pre>
  </div>
</div>
<section
  id="create-custom-text-embedding"
  class="cell-markdown"
  id="b4lCp6OxF8do"
>
  <h4>Create custom text embedding</h4>
</section>
<div
  class="cell-code"
  data-execution_count="39"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="sP6Ypi2-F7gj"
  data-outputId="504751e4-938d-497a-abca-6296748dbe69"
>
  <div class="sourceCode" id="cb65">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create token embedding layer</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>token_embed <span class="op">=</span> layers.Embedding(input_dim<span class="op">=</span><span class="bu">len</span>(rct_20k_text_vocab), <span class="co"># length of vocabulary</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>                               output_dim<span class="op">=</span><span class="dv">128</span>, <span class="co"># Note: different embedding sizes result in drastically different numbers of parameters to train</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># Use masking to handle variable sequence lengths (save space)</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>                               mask_zero<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>                               name<span class="op">=</span><span class="st">&quot;token_embedding&quot;</span>)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Show example embedding</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Sentence before vectorization:</span><span class="ch">\n</span><span class="sc">{</span>target_sentence<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>vectorized_sentence <span class="op">=</span> text_vectorizer([target_sentence])</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Sentence after vectorization (before embedding):</span><span class="ch">\n</span><span class="sc">{</span>vectorized_sentence<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>embedded_sentence <span class="op">=</span> token_embed(vectorized_sentence)</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Sentence after embedding:</span><span class="ch">\n</span><span class="sc">{</span>embedded_sentence<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedded sentence shape: </span><span class="sc">{</span>embedded_sentence<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Sentence before vectorization:
in this prospective , randomized trial , @ patients scheduled for laparoscopic cholecystectomy were assigned to propofol , isoflurane , desflurane , or sevoflurane for the maintenance of anesthesia .

Sentence after vectorization (before embedding):
[[   5   23  241   29   32   12 1141   11  723 2758    9  123    6  914
  4643 4123   16 1818   11    2  627    4  435    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0]]

Sentence after embedding:
[[[-0.0201859  -0.04330238 -0.01437413 ...  0.04945285 -0.01243285
   -0.00956361]
  [ 0.04791344  0.00896294 -0.01840334 ... -0.00713136 -0.03678806
   -0.00544257]
  [-0.02886702 -0.02800328 -0.03195085 ... -0.03046739  0.04015524
    0.00343985]
  ...
  [ 0.01751497 -0.04121046 -0.00770398 ... -0.01626035 -0.01240695
    0.04053936]
  [ 0.01751497 -0.04121046 -0.00770398 ... -0.01626035 -0.01240695
    0.04053936]
  [ 0.01751497 -0.04121046 -0.00770398 ... -0.01626035 -0.01240695
    0.04053936]]]

Embedded sentence shape: (1, 55, 128)
</code></pre>
  </div>
</div>
<section
  id="create-datasets-as-fast-as-possible"
  class="cell-markdown"
  id="_Fke8IZtGH0o"
>
  <h4>Create datasets (as fast as possible)</h4>
</section>
<div
  class="cell-code"
  data-execution_count="40"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="z7T_BwcMF5gW"
  data-outputId="cf4b70d8-47f2-43c6-f7c2-450ad046a45c"
>
  <div class="sourceCode" id="cb67">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn our data into TensorFlow Datasets</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>valid_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>train_dataset</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="40">
    <pre><code>&lt;_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="41"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="EzOE8rF6GZ1e"
  data-outputId="4d0387bd-14a1-4290-f1ca-58fd790fa663"
>
  <div class="sourceCode" id="cb69">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the TensorSliceDataset&#39;s and turn them into prefetched batches</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>valid_dataset <span class="op">=</span> valid_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>train_dataset</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="41">
    <pre><code>&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))&gt;</code></pre>
  </div>
</div>
<div class="cell-markdown" id="LyZdXW2NKMk5">
  <p>
    <img
      src="{% static 'img\skimlit\8842048707ff118f8c08ba0626ae5b671338612f.png' %}"
      alt="WhatsApp Image 2023-04-09 at 15.29.54.jpeg"
    />
  </p>
</div>
<section
  id="model-1-conv1d-with-token-embeddings"
  class="cell-markdown"
  id="vq11b5vKcQLq"
>
  <h3>Model 1: Conv1D with token embeddings</h3>
</section>
<div class="cell-markdown" id="yZ0lUGEFcb1M">
  <p>
    Input (text) -&gt; Tokenize -&gt; Embedding -&gt; Layers -&gt; Output (label
    probability)
  </p>
</div>
<div class="cell-code" data-execution_count="42" id="lzxXLppvcdhw">
  <div class="sourceCode" id="cb71">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 1D convolutional model to process sequences</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>text_vectors <span class="op">=</span> text_vectorizer(inputs) <span class="co"># vectorize text inputs</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>token_embeddings <span class="op">=</span> token_embed(text_vectors) <span class="co"># create embedding</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Conv1D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, padding<span class="op">=</span><span class="st">&quot;same&quot;</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(token_embeddings)</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.GlobalAveragePooling1D()(x) <span class="co"># condense the output of our feature vector</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> layers.Dense(num_classes, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x)</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>model_1 <span class="op">=</span> tf.keras.Model(inputs, outputs)</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>model_1.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;categorical_crossentropy&quot;</span>, <span class="co"># if your labels are integer form (not one hot) use sparse_categorical_crossentropy</span></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>                optimizer<span class="op">=</span>tf.keras.optimizers.Adam(),</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="43"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="vGr-jB52cgae"
  data-outputId="413fea2f-b48a-4af5-90ce-5facf27c9bfc"
>
  <div class="sourceCode" id="cb72">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get summary of Conv1D model</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>model_1.summary()</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1)]               0         
                                                                 
 text_vectorization (TextVec  (None, 55)               0         
 torization)                                                     
                                                                 
 token_embedding (Embedding)  (None, 55, 128)          8299648   
                                                                 
 conv1d (Conv1D)             (None, 55, 64)            41024     
                                                                 
 global_average_pooling1d (G  (None, 64)               0         
 lobalAveragePooling1D)                                          
                                                                 
 dense (Dense)               (None, 5)                 325       
                                                                 
=================================================================
Total params: 8,340,997
Trainable params: 8,340,997
Non-trainable params: 0
_________________________________________________________________
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="44"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="yDc94-MfcjsJ"
  data-outputId="23f75eba-74d7-4daf-d3ec-91323833a0bd"
>
  <div class="sourceCode" id="cb74">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>model_1_history <span class="op">=</span> model_1.fit(train_dataset,</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>                              steps_per_epoch<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(train_dataset)), <span class="co"># only fit on 10% of batches for faster training time</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>                              epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>                              validation_data<span class="op">=</span>valid_dataset,</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>                              validation_steps<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(valid_dataset))) <span class="co"># only validate on 10% of batches</span></span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Epoch 1/3
562/562 [==============================] - 45s 61ms/step - loss: 0.9209 - accuracy: 0.6316 - val_loss: 0.6871 - val_accuracy: 0.7380
Epoch 2/3
562/562 [==============================] - 8s 15ms/step - loss: 0.6608 - accuracy: 0.7537 - val_loss: 0.6377 - val_accuracy: 0.7640
Epoch 3/3
562/562 [==============================] - 5s 9ms/step - loss: 0.6221 - accuracy: 0.7732 - val_loss: 0.6009 - val_accuracy: 0.7839
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="45"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="_HTVhp-VdBCw"
  data-outputId="ead1a60d-3b82-485f-f104-7eb4d32405d8"
>
  <div class="sourceCode" id="cb76">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on whole validation dataset (we only validated on 10% of batches during training)</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>model_1.evaluate(valid_dataset)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 4s 4ms/step - loss: 0.6030 - accuracy: 0.7844
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="45">
    <pre><code>[0.6030129194259644, 0.7843903303146362]</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="46"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="IWgDOfBidDMe"
  data-outputId="3d0c527f-dd0b-4309-dd7d-d4995128aa3d"
>
  <div class="sourceCode" id="cb79">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions (our model outputs prediction probabilities for each class)</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>model_1_pred_probs <span class="op">=</span> model_1.predict(valid_dataset)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>model_1_pred_probs</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 2s 2ms/step
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="46">
    <pre><code>array([[4.4058171e-01, 1.4334297e-01, 9.8325811e-02, 2.9956198e-01,
        1.8187590e-02],
       [4.7654477e-01, 2.6438472e-01, 1.0996968e-02, 2.4159350e-01,
        6.4800256e-03],
       [1.3555121e-01, 7.7639110e-03, 1.0997573e-03, 8.5556328e-01,
        2.1860338e-05],
       ...,
       [2.4830733e-06, 7.0783182e-04, 4.4145004e-04, 2.4633387e-06,
        9.9884570e-01],
       [6.1821081e-02, 3.4271038e-01, 1.6144976e-01, 8.7005138e-02,
        3.4701359e-01],
       [1.6228658e-01, 6.8264514e-01, 2.8216226e-02, 4.1299380e-02,
        8.5552648e-02]], dtype=float32)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="47"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="aHs5XhChdLaU"
  data-outputId="10fc0884-04c2-4639-e2ba-edaea368b9cb"
>
  <div class="sourceCode" id="cb82">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert pred probs to classes</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>model_1_preds <span class="op">=</span> tf.argmax(model_1_pred_probs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>model_1_preds</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="47">
    <pre><code>&lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="48"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="XoGWNEPRdNb2"
  data-outputId="bc1d2c5f-1f76-46e4-ba80-170e4a8c1c36"
>
  <div class="sourceCode" id="cb84">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate model_1 results</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>model_1_results <span class="op">=</span> calculate_results(y_true<span class="op">=</span>val_labels_encoded,</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>                                    y_pred<span class="op">=</span>model_1_preds)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>model_1_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="48">
    <pre><code>{&#39;accuracy&#39;: 78.4390308486694,
 &#39;precision&#39;: 0.780879564706172,
 &#39;recall&#39;: 0.784390308486694,
 &#39;f1&#39;: 0.7820979341266784}</code></pre>
  </div>
</div>
<div class="cell-markdown" id="WathalqjeJGp">
  <p>
    <img
      src="{% static 'img\skimlit\f44f59370cef2898409abfa931a20847fe71a10d.png' %}"
      alt="transfer Learning NLP.png"
    />
  </p>
</div>
<section
  id="model-2-feature-extraction-with-pretrained-token-embeddings"
  class="cell-markdown"
  id="5YKPj8vJdcMy"
>
  <h3>Model 2: Feature extraction with pretrained token embeddings</h3>
</section>
<div class="cell-code" data-execution_count="49" id="3T1XH4KXdixU">
  <div class="sourceCode" id="cb86">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download pretrained TensorFlow Hub USE</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_hub <span class="im">as</span> hub</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>tf_hub_embedding_layer <span class="op">=</span> hub.KerasLayer(<span class="st">&quot;https://tfhub.dev/google/universal-sentence-encoder/4&quot;</span>,</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>                                        trainable<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>                                        name<span class="op">=</span><span class="st">&quot;universal_sentence_encoder&quot;</span>)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="50"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="9Up2YKvAefGm"
  data-outputId="108ce866-c2c6-46ca-e0aa-8437da5684e7"
>
  <div class="sourceCode" id="cb87">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out the embedding on a random sentence</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>random_training_sentence <span class="op">=</span> random.choice(train_sentences)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Random training sentence:</span><span class="ch">\n</span><span class="sc">{</span>random_training_sentence<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>use_embedded_sentence <span class="op">=</span> tf_hub_embedding_layer([random_training_sentence])</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Sentence after embedding:</span><span class="ch">\n</span><span class="sc">{</span>use_embedded_sentence[<span class="dv">0</span>][:<span class="dv">30</span>]<span class="sc">}</span><span class="ss"> (truncated output)...</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Length of sentence embedding:</span><span class="ch">\n</span><span class="sc">{</span><span class="bu">len</span>(use_embedded_sentence[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Random training sentence:
follow-up of a randomized clinical trial conducted from april @ , @ , through may @ , @ , at a swedish county hospital .

Sentence after embedding:
[-0.03250359  0.06878617 -0.00147568 -0.02008413  0.02739096 -0.00292796
 -0.03648011  0.01458557  0.06175242 -0.06853009  0.08834196  0.00133359
  0.0423286   0.07380553  0.01568808  0.00098585 -0.0897999   0.01240763
 -0.05282821 -0.00707323 -0.05473452  0.02722473  0.01377521 -0.02474201
 -0.04646295 -0.02347738 -0.04245216  0.08453546  0.0389693   0.03385064] (truncated output)...

Length of sentence embedding:
512
</code></pre>
  </div>
</div>
<section
  id="building-and-fitting-an-nlp-feature-extraction-model-from-tensorflow-hub"
  class="cell-markdown"
  id="liM6wc5rej-9"
>
  <h4>
    Building and fitting an NLP feature extraction model from TensorFlow Hub
  </h4>
</section>
<div class="cell-code" data-execution_count="51" id="8uE35pSvella">
  <div class="sourceCode" id="cb89">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define feature extractor model using TF Hub layer</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>[], dtype<span class="op">=</span>tf.string)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>pretrained_embedding <span class="op">=</span> tf_hub_embedding_layer(inputs) <span class="co"># tokenize text and create embedding</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(pretrained_embedding) <span class="co"># add a fully connected layer on top of the embedding</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: you could add more layers here if you wanted to</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> layers.Dense(<span class="dv">5</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x) <span class="co"># create the output layer</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>model_2 <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>inputs,</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>                        outputs<span class="op">=</span>outputs)</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model</span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>model_2.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;categorical_crossentropy&quot;</span>,</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>                optimizer<span class="op">=</span>tf.keras.optimizers.Adam(),</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="52"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="e1FMMnfYeomA"
  data-outputId="17f84a76-4d14-4576-bf83-41184297a576"
>
  <div class="sourceCode" id="cb90">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a summary of the model</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>model_2.summary()</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model: &quot;model_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None,)]                 0         
                                                                 
 universal_sentence_encoder   (None, 512)              256797824 
 (KerasLayer)                                                    
                                                                 
 dense_1 (Dense)             (None, 128)               65664     
                                                                 
 dense_2 (Dense)             (None, 5)                 645       
                                                                 
=================================================================
Total params: 256,864,133
Trainable params: 66,309
Non-trainable params: 256,797,824
_________________________________________________________________
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="53"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="L4wQiu1Jep0m"
  data-outputId="436650d8-3b79-47b6-98e3-a34e964060e5"
>
  <div class="sourceCode" id="cb92">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit feature extractor model for 3 epochs</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>model_2_history <span class="op">=</span> model_2.fit(train_dataset,</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>            steps_per_epoch<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(train_dataset)),</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>            epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>            validation_data<span class="op">=</span>valid_dataset,</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>            validation_steps<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(valid_dataset)))</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Epoch 1/3
562/562 [==============================] - 11s 16ms/step - loss: 0.9167 - accuracy: 0.6515 - val_loss: 0.7987 - val_accuracy: 0.6868
Epoch 2/3
562/562 [==============================] - 7s 13ms/step - loss: 0.7697 - accuracy: 0.7007 - val_loss: 0.7571 - val_accuracy: 0.7011
Epoch 3/3
562/562 [==============================] - 9s 16ms/step - loss: 0.7542 - accuracy: 0.7104 - val_loss: 0.7411 - val_accuracy: 0.7138
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="54"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="opzJ7LI-fFJk"
  data-outputId="61925864-a8bb-4fd6-d6c9-e79e5c6cf0b1"
>
  <div class="sourceCode" id="cb94">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on whole validation dataset</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>model_2.evaluate(valid_dataset)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 11s 12ms/step - loss: 0.7430 - accuracy: 0.7127
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="54">
    <pre><code>[0.7430434823036194, 0.7127300500869751]</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="55"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="Jcah5WxpfHe3"
  data-outputId="4c18b28f-91cd-4bf3-a979-8e446b4af413"
>
  <div class="sourceCode" id="cb97">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions with feature extraction model</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>model_2_pred_probs <span class="op">=</span> model_2.predict(valid_dataset)</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>model_2_pred_probs</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 11s 11ms/step
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="55">
    <pre><code>array([[4.2781749e-01, 3.6017692e-01, 2.3129615e-03, 2.0175795e-01,
        7.9346914e-03],
       [3.3440498e-01, 5.1187092e-01, 2.9446150e-03, 1.4759737e-01,
        3.1820952e-03],
       [2.3822533e-01, 1.2464261e-01, 1.7220952e-02, 5.8181250e-01,
        3.8098577e-02],
       ...,
       [1.8471044e-03, 5.9606554e-03, 5.9288014e-02, 7.0927624e-04,
        9.3219495e-01],
       [3.0802460e-03, 4.5865137e-02, 1.7083779e-01, 1.1088441e-03,
        7.7910799e-01],
       [1.6834208e-01, 2.9441640e-01, 4.6485156e-01, 7.5184070e-03,
        6.4871609e-02]], dtype=float32)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="56"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="f03hfmutfIT3"
  data-outputId="0b30babd-9c5f-47c7-e140-97808d38004d"
>
  <div class="sourceCode" id="cb100">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the predictions with feature extraction model to classes</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>model_2_preds <span class="op">=</span> tf.argmax(model_2_pred_probs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>model_2_preds</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="56">
    <pre><code>&lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="57"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="Je6EbtNqfLDg"
  data-outputId="b566ca8f-5b27-4258-9d92-8390ec30c9ac"
>
  <div class="sourceCode" id="cb102">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate results from TF Hub pretrained embeddings results on validation set</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>model_2_results <span class="op">=</span> calculate_results(y_true<span class="op">=</span>val_labels_encoded,</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>                                    y_pred<span class="op">=</span>model_2_preds)</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>model_2_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="57">
    <pre><code>{&#39;accuracy&#39;: 71.2730041043294,
 &#39;precision&#39;: 0.7129642780423172,
 &#39;recall&#39;: 0.7127300410432941,
 &#39;f1&#39;: 0.7098050724245611}</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="58"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="oC-UvE66fhSk"
  data-outputId="9c21d8f4-0269-43b7-ba67-4d3bd80e3120"
>
  <div class="sourceCode" id="cb104">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 1 = </span><span class="sc">{</span>model_1_results<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 2 = </span><span class="sc">{</span>model_2_results<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model 1 = {&#39;accuracy&#39;: 78.4390308486694, &#39;precision&#39;: 0.780879564706172, &#39;recall&#39;: 0.784390308486694, &#39;f1&#39;: 0.7820979341266784}
Model 2 = {&#39;accuracy&#39;: 71.2730041043294, &#39;precision&#39;: 0.7129642780423172, &#39;recall&#39;: 0.7127300410432941, &#39;f1&#39;: 0.7098050724245611}
</code></pre>
  </div>
</div>
<section
  id="model-3-conv1d-with-character-embeddings"
  class="cell-markdown"
  id="TA9v-_mGkBqE"
>
  <h3>Model 3: Conv1D with character embeddings</h3>
</section>
<div class="cell-markdown" id="PCes_nllkXpH">
  <p>
    <img
      src="{% static 'img\skimlit\c745cc9eea570b1ede364ac1833c04cb23757011.png' %}"
      alt="68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d7264626f75726b652f74656e736f72666c6f772d646565702d6c6561726e696e672f6d61696e2f696d616765732f30392d746f6b656e2d76732d636861.png"
    />
  </p>
</div>
<section
  id="creating-a-character-level-tokenizer"
  class="cell-markdown"
  id="13kFZYvVl12s"
>
  <h4>Creating a character-level tokenizer</h4>
</section>
<div
  class="cell-code"
  data-execution_count="59"
  data-colab='{"base_uri":"https://localhost:8080/","height":53}'
  id="wh3-1n-TkhUS"
  data-outputId="d21580a8-9df2-458f-8767-33d678035851"
>
  <div class="sourceCode" id="cb106">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make function to split sentences into characters</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_chars(text):</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="st">&quot; &quot;</span>.join(<span class="bu">list</span>(text))</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test splitting non-character-level sequence into characters</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>split_chars(random_training_sentence)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="59">
    <div class="sourceCode" id="cb107">
      <pre
        class="sourceCode json"
      ><code class="sourceCode json"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre>
    </div>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="60"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="EUGtxS9JmCUc"
  data-outputId="b0e5c4b3-c5a2-48f5-b847-35fcf2dbd55b"
>
  <div class="sourceCode" id="cb108">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split sequence-level data splits into character-level data splits</span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>train_chars <span class="op">=</span> [split_chars(sentence) <span class="cf">for</span> sentence <span class="kw">in</span> train_sentences]</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>val_chars <span class="op">=</span> [split_chars(sentence) <span class="cf">for</span> sentence <span class="kw">in</span> val_sentences]</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>test_chars <span class="op">=</span> [split_chars(sentence) <span class="cf">for</span> sentence <span class="kw">in</span> test_sentences]</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_chars[<span class="dv">0</span>])</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="61"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="egg3FXcDmT18"
  data-outputId="2ebc41e7-d5b6-4882-c6a9-af2a4c383913"
>
  <div class="sourceCode" id="cb110">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What&#39;s the average character length?</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>char_lens <span class="op">=</span> [<span class="bu">len</span>(sentence) <span class="cf">for</span> sentence <span class="kw">in</span> train_sentences]</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>mean_char_len <span class="op">=</span> np.mean(char_lens)</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>mean_char_len</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="61">
    <pre><code>149.3662574983337</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="62"
  data-colab='{"base_uri":"https://localhost:8080/","height":430}'
  id="b04fwgm9uLt-"
  data-outputId="54e2108c-199d-4ce9-fcf5-1db2347c2061"
>
  <div class="sourceCode" id="cb112">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the distribution of our sequences at character-level</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>plt.hist(char_lens, bins<span class="op">=</span><span class="dv">7</span>)<span class="op">;</span></span></code></pre>
  </div>
  <div class="output display_data">
    <p>
      <img
        src="{% static 'img\skimlit\f9b7c60a0807b874c3cb95a902f00a4e584f6b18.png' %}"
      />
    </p>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="63"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="n29ZfuzGuNbC"
  data-outputId="3a6a8676-b5fd-4d70-cc06-c7cbaef112bb"
>
  <div class="sourceCode" id="cb113">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find what character length covers 95% of sequences</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>output_seq_char_len <span class="op">=</span> <span class="bu">int</span>(np.percentile(char_lens, <span class="dv">95</span>))</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>output_seq_char_len</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="63">
    <pre><code>290</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="64"
  data-colab='{"base_uri":"https://localhost:8080/","height":35}'
  id="NTIV7fPfvlik"
  data-outputId="9f2082ad-1611-4991-a4e1-177cf307be65"
>
  <div class="sourceCode" id="cb115">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all keyboard characters for char-level embedding</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>alphabet <span class="op">=</span> string.ascii_lowercase <span class="op">+</span> string.digits <span class="op">+</span> string.punctuation</span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>alphabet</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="64">
    <div class="sourceCode" id="cb116">
      <pre
        class="sourceCode json"
      ><code class="sourceCode json"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre>
    </div>
  </div>
</div>
<div class="cell-code" data-execution_count="65" id="eXYDnwZtvoHX">
  <div class="sourceCode" id="cb117">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create char-level token vectorizer instance</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>NUM_CHAR_TOKENS <span class="op">=</span> <span class="bu">len</span>(alphabet) <span class="op">+</span> <span class="dv">2</span> <span class="co"># num characters in alphabet + space + OOV token</span></span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>char_vectorizer <span class="op">=</span> TextVectorization(max_tokens<span class="op">=</span>NUM_CHAR_TOKENS,</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>                                    output_sequence_length<span class="op">=</span>output_seq_char_len,</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>                                    standardize<span class="op">=</span><span class="st">&quot;lower_and_strip_punctuation&quot;</span>,</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>                                    name<span class="op">=</span><span class="st">&quot;char_vectorizer&quot;</span>)</span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Adapt character vectorizer to training characters</span></span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>char_vectorizer.adapt(train_chars)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="66"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="NNf1C4NHvrAD"
  data-outputId="0e1c69b6-b289-4d61-cf68-d3515535ba80"
>
  <div class="sourceCode" id="cb118">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check character vocabulary characteristics</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>char_vocab <span class="op">=</span> char_vectorizer.get_vocabulary()</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of different characters in character vocab: </span><span class="sc">{</span><span class="bu">len</span>(char_vocab)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;5 most common characters: </span><span class="sc">{</span>char_vocab[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;5 least common characters: </span><span class="sc">{</span>char_vocab[<span class="op">-</span><span class="dv">5</span>:]<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Number of different characters in character vocab: 28
5 most common characters: [&#39;&#39;, &#39;[UNK]&#39;, &#39;e&#39;, &#39;t&#39;, &#39;i&#39;]
5 least common characters: [&#39;k&#39;, &#39;x&#39;, &#39;z&#39;, &#39;q&#39;, &#39;j&#39;]
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="67"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="fzUGIIA0vroo"
  data-outputId="f0f5b1bb-93ab-483b-e9c9-54a58928fbda"
>
  <div class="sourceCode" id="cb120">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out character vectorizer</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>random_train_chars <span class="op">=</span> random.choice(train_chars)</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Charified text:</span><span class="ch">\n</span><span class="sc">{</span>random_train_chars<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Length of chars: </span><span class="sc">{</span><span class="bu">len</span>(random_train_chars.split())<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>vectorized_chars <span class="op">=</span> char_vectorizer([random_train_chars])</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Vectorized chars:</span><span class="ch">\n</span><span class="sc">{</span>vectorized_chars<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Length of vectorized chars: </span><span class="sc">{</span><span class="bu">len</span>(vectorized_chars[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Charified text:
o n e   h u n d r e d   t w e n t y - s i x   p a t i e n t s   w e r e   r a n d o m l y   a s s i g n e d   t o   t r e a t m e n t   (   n   =   @   )   o r   c o n t r o l   (   n   =   @   )   c o n d i t i o n s   .

Length of chars: 89

Vectorized chars:
[[ 7  6  2 13 16  6 10  8  2 10  3 20  2  6  3 19  9  4 24 14  5  3  4  2
   6  3  9 20  2  8  2  8  5  6 10  7 15 12 19  5  9  9  4 18  6  2 10  3
   7  3  8  2  5  3 15  2  6  3  6  7  8 11  7  6  3  8  7 12  6 11  7  6
  10  4  3  4  7  6  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]]

Length of vectorized chars: 290
</code></pre>
  </div>
</div>
<section
  id="creating-a-character-level-embedding"
  class="cell-markdown"
  id="nd3N32ceyU8Z"
>
  <h4>Creating a character-level embedding</h4>
</section>
<div
  class="cell-code"
  data-execution_count="68"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="IsFfs4FhyRxU"
  data-outputId="53978750-6ea2-4e24-d713-cd9a26f05045"
>
  <div class="sourceCode" id="cb122">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create char embedding layer</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>char_embed <span class="op">=</span> layers.Embedding(input_dim<span class="op">=</span>NUM_CHAR_TOKENS, <span class="co"># number of different characters</span></span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>                              output_dim<span class="op">=</span><span class="dv">25</span>, <span class="co"># embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)</span></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>                              mask_zero<span class="op">=</span><span class="va">False</span>, <span class="co"># don&#39;t use masks (this messes up model_5 if set to True)</span></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>                              name<span class="op">=</span><span class="st">&quot;char_embed&quot;</span>)</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out character embedding layer</span></span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Charified text (before vectorization and embedding):</span><span class="ch">\n</span><span class="sc">{</span>random_train_chars<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a>char_embed_example <span class="op">=</span> char_embed(char_vectorizer([random_train_chars]))</span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedded chars (after vectorization and embedding):</span><span class="ch">\n</span><span class="sc">{</span>char_embed_example<span class="sc">}</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Character embedding shape: </span><span class="sc">{</span>char_embed_example<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Charified text (before vectorization and embedding):
o n e   h u n d r e d   t w e n t y - s i x   p a t i e n t s   w e r e   r a n d o m l y   a s s i g n e d   t o   t r e a t m e n t   (   n   =   @   )   o r   c o n t r o l   (   n   =   @   )   c o n d i t i o n s   .

Embedded chars (after vectorization and embedding):
[[[-0.04819924  0.02301692  0.04429896 ...  0.01583928  0.02966324
   -0.02954452]
  [-0.01979551 -0.03983741 -0.02779811 ... -0.00684629 -0.00087036
   -0.00795071]
  [-0.00609834  0.04702891 -0.04847625 ...  0.00130833  0.0488205
    0.02252293]
  ...
  [ 0.02396197  0.00145353 -0.01397104 ... -0.04566852  0.03025342
    0.02010183]
  [ 0.02396197  0.00145353 -0.01397104 ... -0.04566852  0.03025342
    0.02010183]
  [ 0.02396197  0.00145353 -0.01397104 ... -0.04566852  0.03025342
    0.02010183]]]

Character embedding shape: (1, 290, 25)
</code></pre>
  </div>
</div>
<section
  id="building-a-conv1d-model-to-fit-on-character-embeddings"
  class="cell-markdown"
  id="yr2asgdPybl2"
>
  <h4>Building a Conv1D model to fit on character embeddings</h4>
</section>
<div class="cell-code" data-execution_count="69" id="zBtvRWd-yfe1">
  <div class="sourceCode" id="cb124">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make Conv1D on chars only</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span><span class="st">&quot;string&quot;</span>)</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>char_vectors <span class="op">=</span> char_vectorizer(inputs)</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>char_embeddings <span class="op">=</span> char_embed(char_vectors)</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Conv1D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, padding<span class="op">=</span><span class="st">&quot;same&quot;</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(char_embeddings)</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.GlobalMaxPool1D()(x)</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> layers.Dense(num_classes, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x)</span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>model_3 <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>inputs,</span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>                         outputs<span class="op">=</span>outputs,</span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>                         name<span class="op">=</span><span class="st">&quot;model_3_conv1D_char_embedding&quot;</span>)</span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-12"><a href="#cb124-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile model</span></span>
<span id="cb124-13"><a href="#cb124-13" aria-hidden="true" tabindex="-1"></a>model_3.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;categorical_crossentropy&quot;</span>,</span>
<span id="cb124-14"><a href="#cb124-14" aria-hidden="true" tabindex="-1"></a>                optimizer<span class="op">=</span>tf.keras.optimizers.Adam(),</span>
<span id="cb124-15"><a href="#cb124-15" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="70"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="jwoWnlmjygIc"
  data-outputId="55d7292c-d2a2-4df4-deb9-0a098c209545"
>
  <div class="sourceCode" id="cb125">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the summary of conv1d_char_model</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>model_3.summary()</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model: &quot;model_3_conv1D_char_embedding&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 1)]               0         
                                                                 
 char_vectorizer (TextVector  (None, 290)              0         
 ization)                                                        
                                                                 
 char_embed (Embedding)      (None, 290, 25)           1750      
                                                                 
 conv1d_1 (Conv1D)           (None, 290, 64)           8064      
                                                                 
 global_max_pooling1d (Globa  (None, 64)               0         
 lMaxPooling1D)                                                  
                                                                 
 dense_3 (Dense)             (None, 5)                 325       
                                                                 
=================================================================
Total params: 10,139
Trainable params: 10,139
Non-trainable params: 0
_________________________________________________________________
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="71"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="wQW2mc6hyiDo"
  data-outputId="cd9b112e-86e2-4411-ed64-ac451d11c4cd"
>
  <div class="sourceCode" id="cb127">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create char datasets</span></span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>train_char_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>val_char_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>train_char_dataset</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="71">
    <pre><code>&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="72"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="zxuxcFnTylEW"
  data-outputId="877d9616-e03c-47dc-9bff-436fd7d78faf"
>
  <div class="sourceCode" id="cb129">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model on chars only</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>model_3_history <span class="op">=</span> model_3.fit(train_char_dataset,</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>                              steps_per_epoch<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(train_char_dataset)),</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>                              epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>                              validation_data<span class="op">=</span>val_char_dataset,</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>                              validation_steps<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(val_char_dataset)))</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Epoch 1/3
562/562 [==============================] - 5s 7ms/step - loss: 1.2615 - accuracy: 0.4843 - val_loss: 1.0545 - val_accuracy: 0.5751
Epoch 2/3
562/562 [==============================] - 4s 7ms/step - loss: 1.0236 - accuracy: 0.5899 - val_loss: 0.9519 - val_accuracy: 0.6307
Epoch 3/3
562/562 [==============================] - 3s 5ms/step - loss: 0.9407 - accuracy: 0.6315 - val_loss: 0.8841 - val_accuracy: 0.6582
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="73"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="DeyKzpOx4g4i"
  data-outputId="e78a171c-28c7-41ef-b1e0-f68513a1c251"
>
  <div class="sourceCode" id="cb131">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate model_3 on whole validation char dataset</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>model_3.evaluate(val_char_dataset)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 4s 4ms/step - loss: 0.8932 - accuracy: 0.6521
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="73">
    <pre><code>[0.8931640982627869, 0.6521250009536743]</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="74"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="rTEy0X2N5dW-"
  data-outputId="8bae31ae-7368-4ec8-d5b7-8f17fc8f77ee"
>
  <div class="sourceCode" id="cb134">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions with character model only</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>model_3_pred_probs <span class="op">=</span> model_3.predict(val_char_dataset)</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>model_3_pred_probs</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 3s 3ms/step
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="74">
    <pre><code>array([[0.1891718 , 0.42304903, 0.08839776, 0.2723321 , 0.02704929],
       [0.16538374, 0.55897486, 0.03748208, 0.13056825, 0.10759113],
       [0.10229483, 0.525668  , 0.04057477, 0.24839096, 0.08307149],
       ...,
       [0.05579031, 0.07969639, 0.15054332, 0.06837955, 0.6455904 ],
       [0.06671614, 0.27256015, 0.2493481 , 0.03365253, 0.37772304],
       [0.40557402, 0.48624277, 0.02649043, 0.07791143, 0.00378144]],
      dtype=float32)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="75"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="QGrIrh-U5iYO"
  data-outputId="d684e73a-ce59-4b55-d2a2-123411502113"
>
  <div class="sourceCode" id="cb137">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert predictions to classes</span></span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>model_3_preds <span class="op">=</span> tf.argmax(model_3_pred_probs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a>model_3_preds</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="75">
    <pre><code>&lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 1, ..., 4, 4, 1])&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="76"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="Gea710Rj5kLc"
  data-outputId="2c74f514-aa55-4e82-cc34-9623ac348f5c"
>
  <div class="sourceCode" id="cb139">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Conv1D char only model results</span></span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>model_3_results <span class="op">=</span> calculate_results(y_true<span class="op">=</span>val_labels_encoded,</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>                                        y_pred<span class="op">=</span>model_3_preds)</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>model_3_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="76">
    <pre><code>{&#39;accuracy&#39;: 65.21249834502846,
 &#39;precision&#39;: 0.6458398557290344,
 &#39;recall&#39;: 0.6521249834502847,
 &#39;f1&#39;: 0.6421413543282711}</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="77"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="-zRXIZB650cl"
  data-outputId="f6516d55-937b-417c-ffce-be5d05abef89"
>
  <div class="sourceCode" id="cb141">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 1 = </span><span class="sc">{</span>model_1_results<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 2 = </span><span class="sc">{</span>model_2_results<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 3 = </span><span class="sc">{</span>model_3_results<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model 1 = {&#39;accuracy&#39;: 78.4390308486694, &#39;precision&#39;: 0.780879564706172, &#39;recall&#39;: 0.784390308486694, &#39;f1&#39;: 0.7820979341266784}
Model 2 = {&#39;accuracy&#39;: 71.2730041043294, &#39;precision&#39;: 0.7129642780423172, &#39;recall&#39;: 0.7127300410432941, &#39;f1&#39;: 0.7098050724245611}
Model 3 = {&#39;accuracy&#39;: 65.21249834502846, &#39;precision&#39;: 0.6458398557290344, &#39;recall&#39;: 0.6521249834502847, &#39;f1&#39;: 0.6421413543282711}
</code></pre>
  </div>
</div>
<section
  id="model-4-combining-pretrained-token-embeddings--character-embeddings-hybrid-embedding-layer"
  class="cell-markdown"
  id="bGQ7VMAx55Pv"
>
  <h3>
    Model 4: Combining pretrained token embeddings + character embeddings
    (hybrid embedding layer)
  </h3>
</section>
<div class="cell-markdown" id="G1r0cASiAkfH">
  <p>
    To start replicating (or getting close to replicating) the model in Figure
    1, we're going to go through the following steps:
  </p>
  <ol>
    <li>Create a token-level model (similar to model_1)</li>
    <li>
      Create a character-level model (similar to model_3 with a slight
      modification to reflect the paper)
    </li>
    <li>Combine (using layers.Concatenate) the outputs of 1 and 2</li>
    <li>
      Build a series of output layers on top of 3 similar to Figure 1 and
      section 4.2 of
      <a href="https://arxiv.org/pdf/1612.05251.pdf"
        ><em
          >Neural Networks for Joint Sentence Classification in Medical Paper
          Abstracts</em
        ></a
      >
    </li>
    <li>
      Construct a model which takes token and character-level sequences as input
      and produces sequence label probabilities as output
    </li>
  </ol>
</div>
<div class="cell-code" data-execution_count="78" id="BVewavfe6UwA">
  <div class="sourceCode" id="cb143">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Setup token inputs/model</span></span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>token_inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>[], dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">&quot;token_input&quot;</span>)</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>token_embeddings <span class="op">=</span> tf_hub_embedding_layer(token_inputs)</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a>token_output <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(token_embeddings)</span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>token_model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>token_inputs,</span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>                             outputs<span class="op">=</span>token_output)</span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Setup char inputs/model</span></span>
<span id="cb143-9"><a href="#cb143-9" aria-hidden="true" tabindex="-1"></a>char_inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">&quot;char_input&quot;</span>)</span>
<span id="cb143-10"><a href="#cb143-10" aria-hidden="true" tabindex="-1"></a>char_vectors <span class="op">=</span> char_vectorizer(char_inputs)</span>
<span id="cb143-11"><a href="#cb143-11" aria-hidden="true" tabindex="-1"></a>char_embeddings <span class="op">=</span> char_embed(char_vectors)</span>
<span id="cb143-12"><a href="#cb143-12" aria-hidden="true" tabindex="-1"></a>char_bi_lstm <span class="op">=</span> layers.Bidirectional(layers.LSTM(<span class="dv">25</span>))(char_embeddings) <span class="co"># bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf</span></span>
<span id="cb143-13"><a href="#cb143-13" aria-hidden="true" tabindex="-1"></a>char_model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>char_inputs,</span>
<span id="cb143-14"><a href="#cb143-14" aria-hidden="true" tabindex="-1"></a>                            outputs<span class="op">=</span>char_bi_lstm)</span>
<span id="cb143-15"><a href="#cb143-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-16"><a href="#cb143-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Concatenate token and char inputs (create hybrid token embedding)</span></span>
<span id="cb143-17"><a href="#cb143-17" aria-hidden="true" tabindex="-1"></a>token_char_concat <span class="op">=</span> layers.Concatenate(name<span class="op">=</span><span class="st">&quot;token_char_hybrid&quot;</span>)([token_model.output,</span>
<span id="cb143-18"><a href="#cb143-18" aria-hidden="true" tabindex="-1"></a>                                                                  char_model.output])</span>
<span id="cb143-19"><a href="#cb143-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-20"><a href="#cb143-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf</span></span>
<span id="cb143-21"><a href="#cb143-21" aria-hidden="true" tabindex="-1"></a>combined_dropout <span class="op">=</span> layers.Dropout(<span class="fl">0.5</span>)(token_char_concat)</span>
<span id="cb143-22"><a href="#cb143-22" aria-hidden="true" tabindex="-1"></a>combined_dense <span class="op">=</span> layers.Dense(<span class="dv">200</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(combined_dropout) <span class="co"># slightly different to Figure 1 due to different shapes of token/char embedding layers</span></span>
<span id="cb143-23"><a href="#cb143-23" aria-hidden="true" tabindex="-1"></a>final_dropout <span class="op">=</span> layers.Dropout(<span class="fl">0.5</span>)(combined_dense)</span>
<span id="cb143-24"><a href="#cb143-24" aria-hidden="true" tabindex="-1"></a>output_layer <span class="op">=</span> layers.Dense(num_classes, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(final_dropout)</span>
<span id="cb143-25"><a href="#cb143-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-26"><a href="#cb143-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Construct model with char and token inputs</span></span>
<span id="cb143-27"><a href="#cb143-27" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[token_model.<span class="bu">input</span>, char_model.<span class="bu">input</span>],</span>
<span id="cb143-28"><a href="#cb143-28" aria-hidden="true" tabindex="-1"></a>                         outputs<span class="op">=</span>output_layer,</span>
<span id="cb143-29"><a href="#cb143-29" aria-hidden="true" tabindex="-1"></a>                         name<span class="op">=</span><span class="st">&quot;model_4_token_and_char_embeddings&quot;</span>)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="79"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="1gNr8O9A6cQZ"
  data-outputId="8013f8f2-e2ef-4231-f9dc-47f4980b6249"
>
  <div class="sourceCode" id="cb144">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get summary of token and character model</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>model_4.summary()</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model: &quot;model_4_token_and_char_embeddings&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 char_input (InputLayer)        [(None, 1)]          0           []                               
                                                                                                  
 token_input (InputLayer)       [(None,)]            0           []                               
                                                                                                  
 char_vectorizer (TextVectoriza  (None, 290)         0           [&#39;char_input[0][0]&#39;]             
 tion)                                                                                            
                                                                                                  
 universal_sentence_encoder (Ke  (None, 512)         256797824   [&#39;token_input[0][0]&#39;]            
 rasLayer)                                                                                        
                                                                                                  
 char_embed (Embedding)         (None, 290, 25)      1750        [&#39;char_vectorizer[1][0]&#39;]        
                                                                                                  
 dense_4 (Dense)                (None, 128)          65664       [&#39;universal_sentence_encoder[1][0
                                                                 ]&#39;]                              
                                                                                                  
 bidirectional (Bidirectional)  (None, 50)           10200       [&#39;char_embed[1][0]&#39;]             
                                                                                                  
 token_char_hybrid (Concatenate  (None, 178)         0           [&#39;dense_4[0][0]&#39;,                
 )                                                                &#39;bidirectional[0][0]&#39;]          
                                                                                                  
 dropout (Dropout)              (None, 178)          0           [&#39;token_char_hybrid[0][0]&#39;]      
                                                                                                  
 dense_5 (Dense)                (None, 200)          35800       [&#39;dropout[0][0]&#39;]                
                                                                                                  
 dropout_1 (Dropout)            (None, 200)          0           [&#39;dense_5[0][0]&#39;]                
                                                                                                  
 dense_6 (Dense)                (None, 5)            1005        [&#39;dropout_1[0][0]&#39;]              
                                                                                                  
==================================================================================================
Total params: 256,912,243
Trainable params: 114,419
Non-trainable params: 256,797,824
__________________________________________________________________________________________________
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="80"
  data-colab='{"base_uri":"https://localhost:8080/","height":856}'
  id="q9OuzqBB6cyU"
  data-outputId="caf92c64-f455-4dc9-dc92-3286ddd2b44b"
>
  <div class="sourceCode" id="cb146">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot hybrid token and character model</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> plot_model</span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>plot_model(model_4)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="80">
    <p>
      <img
        src="{% static 'img\skimlit\e1d1d134bc2ec75ed7684d06a2c84edf5986ae61.png' %}"
      />
    </p>
  </div>
</div>
<div class="cell-code" data-execution_count="81" id="TexZy8jBtH59">
  <div class="sourceCode" id="cb147">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile token char model</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>model_4.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;categorical_crossentropy&quot;</span>,</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>                optimizer<span class="op">=</span>tf.keras.optimizers.Adam(), <span class="co"># section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we&#39;ll stick with Adam</span></span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span></code></pre>
  </div>
</div>
<section
  id="combining-token-and-character-data-into-a-tfdata-dataset"
  class="cell-markdown"
  id="955C4tIItMbm"
>
  <h4>Combining token and character data into a tf.data dataset</h4>
</section>
<div class="cell-code" data-execution_count="82" id="KmNPE1OktQLM">
  <div class="sourceCode" id="cb148">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine chars and tokens into a dataset</span></span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>train_char_token_data <span class="op">=</span> tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) <span class="co"># make data</span></span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>train_char_token_labels <span class="op">=</span> tf.data.Dataset.from_tensor_slices(train_labels_one_hot) <span class="co"># make labels</span></span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>train_char_token_dataset <span class="op">=</span> tf.data.Dataset.<span class="bu">zip</span>((train_char_token_data, train_char_token_labels)) <span class="co"># combine data and labels</span></span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Prefetch and batch train data</span></span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>train_char_token_dataset <span class="op">=</span> train_char_token_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb148-8"><a href="#cb148-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-9"><a href="#cb148-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Repeat same steps validation data</span></span>
<span id="cb148-10"><a href="#cb148-10" aria-hidden="true" tabindex="-1"></a>val_char_token_data <span class="op">=</span> tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))</span>
<span id="cb148-11"><a href="#cb148-11" aria-hidden="true" tabindex="-1"></a>val_char_token_labels <span class="op">=</span> tf.data.Dataset.from_tensor_slices(val_labels_one_hot)</span>
<span id="cb148-12"><a href="#cb148-12" aria-hidden="true" tabindex="-1"></a>val_char_token_dataset <span class="op">=</span> tf.data.Dataset.<span class="bu">zip</span>((val_char_token_data, val_char_token_labels))</span>
<span id="cb148-13"><a href="#cb148-13" aria-hidden="true" tabindex="-1"></a>val_char_token_dataset <span class="op">=</span> val_char_token_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="83"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="61BsjelItSgs"
  data-outputId="2eebe684-179d-4a66-a814-3cd6b97e75d9"
>
  <div class="sourceCode" id="cb149">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check out training char and token embedding dataset</span></span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>train_char_token_dataset, val_char_token_dataset</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="83">
    <pre><code>(&lt;_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))&gt;,
 &lt;_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))&gt;)</code></pre>
  </div>
</div>
<section
  id="fitting-a-model-on-token-and-character-level-sequences"
  class="cell-markdown"
  id="sYj1Zbm4tVE8"
>
  <h4>Fitting a model on token and character-level sequences</h4>
</section>
<div
  class="cell-code"
  data-execution_count="84"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="6Re9YUrltYaj"
  data-outputId="c4431d19-e989-4833-a615-ae6c839a1300"
>
  <div class="sourceCode" id="cb151">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model on tokens and chars</span></span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>model_4_history <span class="op">=</span> model_4.fit(train_char_token_dataset, <span class="co"># train on dataset of token and characters</span></span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>                              steps_per_epoch<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(train_char_token_dataset)),</span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>                              epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>                              validation_data<span class="op">=</span>val_char_token_dataset,</span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a>                              validation_steps<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(val_char_token_dataset)))</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Epoch 1/3
562/562 [==============================] - 28s 37ms/step - loss: 0.9712 - accuracy: 0.6128 - val_loss: 0.7739 - val_accuracy: 0.6995
Epoch 2/3
562/562 [==============================] - 18s 32ms/step - loss: 0.7889 - accuracy: 0.6953 - val_loss: 0.7106 - val_accuracy: 0.7320
Epoch 3/3
562/562 [==============================] - 19s 34ms/step - loss: 0.7712 - accuracy: 0.7058 - val_loss: 0.6901 - val_accuracy: 0.7390
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="85"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="ls0gAIbKtzIL"
  data-outputId="e9853067-c152-4fbb-cb9d-a31b57c61d15"
>
  <div class="sourceCode" id="cb153">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on the whole validation dataset</span></span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>model_4.evaluate(val_char_token_dataset)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 18s 19ms/step - loss: 0.6994 - accuracy: 0.7342
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="85">
    <pre><code>[0.6994210481643677, 0.7341784834861755]</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="86"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="4C0HLCKJtzvw"
  data-outputId="c5b3d22d-a295-4172-8728-31cbbd714835"
>
  <div class="sourceCode" id="cb156">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions using the token-character model hybrid</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>model_4_pred_probs <span class="op">=</span> model_4.predict(val_char_token_dataset)</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>model_4_pred_probs</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 20s 20ms/step
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="86">
    <pre><code>array([[4.1725993e-01, 3.6480311e-01, 2.4441460e-03, 2.0824300e-01,
        7.2497730e-03],
       [3.2854575e-01, 4.3185598e-01, 1.8007413e-03, 2.3632285e-01,
        1.4746608e-03],
       [3.0953798e-01, 1.2050761e-01, 3.3218592e-02, 5.0132644e-01,
        3.5409324e-02],
       ...,
       [1.0265989e-03, 8.3891265e-03, 7.1412787e-02, 4.5819630e-04,
        9.1871333e-01],
       [5.1545110e-03, 6.8268515e-02, 1.7864808e-01, 2.8012367e-03,
        7.4512768e-01],
       [3.5228711e-01, 3.7787259e-01, 1.8741800e-01, 4.2084828e-02,
        4.0337466e-02]], dtype=float32)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="87"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="IlU0UJayt2Jh"
  data-outputId="64855ee2-882d-437d-bf04-8c73eb543913"
>
  <div class="sourceCode" id="cb159">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn prediction probabilities into prediction classes</span></span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>model_4_preds <span class="op">=</span> tf.argmax(model_4_pred_probs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a>model_4_preds</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="87">
    <pre><code>&lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="88"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="uKf8RxJpuyKU"
  data-outputId="d591c513-9e64-47d1-befe-7dfd1f2e62df"
>
  <div class="sourceCode" id="cb161">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Conv1D char only model results</span></span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>model_4_results <span class="op">=</span> calculate_results(y_true<span class="op">=</span>val_labels_encoded,</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>                                        y_pred<span class="op">=</span>model_4_preds)</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>model_4_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="88">
    <pre><code>{&#39;accuracy&#39;: 73.41784721302793,
 &#39;precision&#39;: 0.7358619807879756,
 &#39;recall&#39;: 0.7341784721302793,
 &#39;f1&#39;: 0.7322509136268361}</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="89"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="xc6M7Fm8t4W5"
  data-outputId="d4e16b87-30cc-4af2-ea7a-06fed91a464f"
>
  <div class="sourceCode" id="cb163">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 1 = </span><span class="sc">{</span>model_1_results<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 2 = </span><span class="sc">{</span>model_2_results<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 3 = </span><span class="sc">{</span>model_3_results<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Model 4 = </span><span class="sc">{</span>model_4_results<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model 1 = {&#39;accuracy&#39;: 78.4390308486694, &#39;precision&#39;: 0.780879564706172, &#39;recall&#39;: 0.784390308486694, &#39;f1&#39;: 0.7820979341266784}
Model 2 = {&#39;accuracy&#39;: 71.2730041043294, &#39;precision&#39;: 0.7129642780423172, &#39;recall&#39;: 0.7127300410432941, &#39;f1&#39;: 0.7098050724245611}
Model 3 = {&#39;accuracy&#39;: 65.21249834502846, &#39;precision&#39;: 0.6458398557290344, &#39;recall&#39;: 0.6521249834502847, &#39;f1&#39;: 0.6421413543282711}
Model 4 = {&#39;accuracy&#39;: 73.41784721302793, &#39;precision&#39;: 0.7358619807879756, &#39;recall&#39;: 0.7341784721302793, &#39;f1&#39;: 0.7322509136268361}
</code></pre>
  </div>
</div>
<section
  id="model-5-transfer-learning-with-pretrained-token-embeddings--character-embeddings--positional-embeddings"
  class="cell-markdown"
  id="DkhQY1trGqp4"
>
  <h3>
    Model 5: Transfer Learning with pretrained token embeddings + character
    embeddings + positional embeddings
  </h3>
</section>
<div class="cell-markdown" id="ceVcGxMrG1V9">
  <p>
    If you were to look at an abstract, would you expect the sentences to appear
    in order? Or does it make sense if they were to appear sequentially? For
    example, sequences labelled CONCLUSIONS at the beggining and sequences
    labelled OBJECTIVE at the end?
  </p>
  <p>Abstracts typically come in a sequential order, such as:</p>
  <ul>
    <li>OBJECTIVE ...</li>
    <li>METHODS ...</li>
    <li>METHODS ...</li>
    <li>METHODS ...</li>
    <li>RESULTS ...</li>
    <li>CONCLUSIONS ...</li>
  </ul>
  <p>Or</p>
  <ul>
    <li>BACKGROUND ...</li>
    <li>OBJECTIVE ...</li>
    <li>METHODS ...</li>
    <li>METHODS ...</li>
    <li>RESULTS ...</li>
    <li>RESULTS ...</li>
    <li>CONCLUSIONS ...</li>
    <li>CONCLUSIONS ...</li>
  </ul>
</div>
<div class="cell-markdown" id="JeGZh6tpHOE6">
  <p>
    <img
      src="{% static 'img\skimlit\9e41bcd26ed0ffe08b245c913806a5e2f5a8d8ae.png' %}"
      alt="68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d7264626f75726b652f74656e736f72666c6f772d646565702d6c6561726e696e672f6d61696e2f696d616765732f30392d656e67696e65657265642d66.png"
    />
  </p>
</div>
<div
  class="cell-code"
  data-execution_count="90"
  data-colab='{"base_uri":"https://localhost:8080/","height":206}'
  id="didSOYcxG1yB"
  data-outputId="7133f3bc-cd40-4da7-ee7b-738ea01d9d2e"
>
  <div class="sourceCode" id="cb165">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect training dataframe</span></span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>train_df.head()</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="90">
    <div id="df-cb8904d7-0536-4e1e-9903-8f860e80994a">
      <div class="colab-df-container">
        <div>
          <style scoped>
            .dataframe tbody tr th:only-of-type {
              vertical-align: middle;
            }

            .dataframe tbody tr th {
              vertical-align: top;
            }

            .dataframe thead th {
              text-align: right;
            }
          </style>
          <table border="1" class="dataframe">
            <thead>
              <tr style="text-align: right">
                <th></th>
                <th>target</th>
                <th>text</th>
                <th>line_number</th>
                <th>total_lines</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th>0</th>
                <td>OBJECTIVE</td>
                <td>to investigate the efficacy of @ weeks of dail...</td>
                <td>0</td>
                <td>11</td>
              </tr>
              <tr>
                <th>1</th>
                <td>METHODS</td>
                <td>a total of @ patients with primary knee oa wer...</td>
                <td>1</td>
                <td>11</td>
              </tr>
              <tr>
                <th>2</th>
                <td>METHODS</td>
                <td>outcome measures included pain reduction and i...</td>
                <td>2</td>
                <td>11</td>
              </tr>
              <tr>
                <th>3</th>
                <td>METHODS</td>
                <td>pain was assessed using the visual analog pain...</td>
                <td>3</td>
                <td>11</td>
              </tr>
              <tr>
                <th>4</th>
                <td>METHODS</td>
                <td>secondary outcome measures included the wester...</td>
                <td>4</td>
                <td>11</td>
              </tr>
            </tbody>
          </table>
        </div>
        <button
          class="colab-df-convert"
          onclick="convertToInteractive('df-cb8904d7-0536-4e1e-9903-8f860e80994a')"
          title="Convert this dataframe to an interactive table."
          style="display: none"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            height="24px"
            viewBox="0 0 24 24"
            width="24px"
          >
            <path d="M0 0h24v24H0V0z" fill="none" />
            <path
              d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"
            />
            <path
              d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"
            />
          </svg>
        </button>

        <div id="df-2599a0c7-66f5-4c34-b3a1-342aa4e89f8a">
          <button
            class="colab-df-quickchart"
            onclick="quickchart('df-2599a0c7-66f5-4c34-b3a1-342aa4e89f8a')"
            title="Suggest charts."
            style="display: none"
          >
            <svg
              xmlns="http://www.w3.org/2000/svg"
              height="24px"
              viewBox="0 0 24 24"
              width="24px"
            >
              <g>
                <path
                  d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"
                />
              </g>
            </svg>
          </button>
        </div>

        <style>
          .colab-df-quickchart {
            background-color: #e8f0fe;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            fill: #1967d2;
            height: 32px;
            padding: 0 0 0 0;
            width: 32px;
          }

          .colab-df-quickchart:hover {
            background-color: #e2ebfa;
            box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3),
              0px 1px 3px 1px rgba(60, 64, 67, 0.15);
            fill: #174ea6;
          }

          [theme="dark"] .colab-df-quickchart {
            background-color: #3b4455;
            fill: #d2e3fc;
          }

          [theme="dark"] .colab-df-quickchart:hover {
            background-color: #434b5c;
            box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
            filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
            fill: #ffffff;
          }
        </style>

        <script>
          async function quickchart(key) {
            const containerElement = document.querySelector("#" + key);
            const charts = await google.colab.kernel.invokeFunction(
              "suggestCharts",
              [key],
              {}
            );
          }
        </script>

        <script>
          function displayQuickchartButton(domScope) {
            let quickchartButtonEl = domScope.querySelector(
              "#df-2599a0c7-66f5-4c34-b3a1-342aa4e89f8a button.colab-df-quickchart"
            );
            quickchartButtonEl.style.display = google.colab.kernel.accessAllowed
              ? "block"
              : "none";
          }

          displayQuickchartButton(document);
        </script>
        <style>
          .colab-df-container {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
          }

          .colab-df-convert {
            background-color: #e8f0fe;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            fill: #1967d2;
            height: 32px;
            padding: 0 0 0 0;
            width: 32px;
          }

          .colab-df-convert:hover {
            background-color: #e2ebfa;
            box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3),
              0px 1px 3px 1px rgba(60, 64, 67, 0.15);
            fill: #174ea6;
          }

          [theme="dark"] .colab-df-convert {
            background-color: #3b4455;
            fill: #d2e3fc;
          }

          [theme="dark"] .colab-df-convert:hover {
            background-color: #434b5c;
            box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
            filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
            fill: #ffffff;
          }
        </style>

        <script>
          const buttonEl = document.querySelector(
            "#df-cb8904d7-0536-4e1e-9903-8f860e80994a button.colab-df-convert"
          );
          buttonEl.style.display = google.colab.kernel.accessAllowed
            ? "block"
            : "none";

          async function convertToInteractive(key) {
            const element = document.querySelector(
              "#df-cb8904d7-0536-4e1e-9903-8f860e80994a"
            );
            const dataTable = await google.colab.kernel.invokeFunction(
              "convertToInteractive",
              [key],
              {}
            );
            if (!dataTable) return;

            const docLinkHtml =
              "Like what you see? Visit the " +
              '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>' +
              " to learn more about interactive tables.";
            element.innerHTML = "";
            dataTable["output_type"] = "display_data";
            await google.colab.output.renderOutput(dataTable, element);
            const docLink = document.createElement("div");
            docLink.innerHTML = docLinkHtml;
            element.appendChild(docLink);
          }
        </script>
      </div>
    </div>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="91"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="MWrT5oboLMBq"
  data-outputId="912af0ed-314b-47eb-a117-6921acfbd183"
>
  <div class="sourceCode" id="cb166">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>train_df.shape</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="91">
    <pre><code>(180040, 4)</code></pre>
  </div>
</div>
<section
  id="create-positional-embeddings"
  class="cell-markdown"
  id="7kxcMB0BIfgK"
>
  <h4>Create positional embeddings</h4>
</section>
<div
  class="cell-code"
  data-execution_count="92"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="hltUrK0JHIi5"
  data-outputId="b38dc152-a54f-4d1a-9314-46b38f9018db"
>
  <div class="sourceCode" id="cb168">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many different line numbers are there?</span></span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">&quot;line_number&quot;</span>].value_counts()</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="92">
    <pre><code>0     15000
1     15000
2     15000
3     15000
4     14992
5     14949
6     14758
7     14279
8     13346
9     11981
10    10041
11     7892
12     5853
13     4152
14     2835
15     1861
16     1188
17      751
18      462
19      286
20      162
21      101
22       66
23       33
24       22
25       14
26        7
27        4
28        3
29        1
30        1
Name: line_number, dtype: int64</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="93"
  data-colab='{"base_uri":"https://localhost:8080/","height":447}'
  id="tSL0cRpiKiIs"
  data-outputId="9c3f9b03-a913-45fe-a0f5-609fe3b31960"
>
  <div class="sourceCode" id="cb170">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the distribution of &quot;line_number&quot; column</span></span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>train_df.line_number.plot.hist()</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="93">
    <pre><code>&lt;Axes: ylabel=&#39;Frequency&#39;&gt;</code></pre>
  </div>
  <div class="output display_data">
    <p>
      <img
        src="{% static 'img\skimlit\1997b89c072be287a93687393285aa9730cb4351.png' %}"
      />
    </p>
  </div>
</div>
<div class="cell-code" data-execution_count="94" id="SGMmTEX9Kpqg">
  <div class="sourceCode" id="cb172">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use TensorFlow to create one-hot-encoded tensors of our &quot;line_number&quot; column</span></span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>train_line_numbers_one_hot <span class="op">=</span> tf.one_hot(train_df[<span class="st">&quot;line_number&quot;</span>].to_numpy(), depth<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>val_line_numbers_one_hot <span class="op">=</span> tf.one_hot(val_df[<span class="st">&quot;line_number&quot;</span>].to_numpy(), depth<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>test_line_numbers_one_hot <span class="op">=</span> tf.one_hot(test_df[<span class="st">&quot;line_number&quot;</span>].to_numpy(), depth<span class="op">=</span><span class="dv">15</span>)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="95"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="kqbQiZ8OKqWo"
  data-outputId="b8e49a7b-1820-4e49-b205-3c1adf908a5d"
>
  <div class="sourceCode" id="cb173">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check one-hot encoded &quot;line_number&quot; feature samples</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:<span class="dv">20</span>]</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="95">
    <pre><code>(TensorShape([180040, 15]),
 &lt;tf.Tensor: shape=(20, 15), dtype=float32, numpy=
 array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],
       dtype=float32)&gt;)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="96"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="XpdWPHkrKsZZ"
  data-outputId="11fad23b-9a37-4219-ae6c-de2755638689"
>
  <div class="sourceCode" id="cb175">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many different numbers of lines are there?</span></span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">&quot;total_lines&quot;</span>].value_counts()</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="96">
    <pre><code>11    24468
10    23639
12    22113
9     19400
13    18438
14    14610
8     12285
15    10768
7      7464
16     7429
17     5202
6      3353
18     3344
19     2480
20     1281
5      1146
21      770
22      759
23      264
4       215
24      200
25      182
26       81
28       58
3        32
30       31
27       28
Name: total_lines, dtype: int64</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="97" id="EaXAqhb_LptU">
  <div class="sourceCode" id="cb177">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use TensorFlow to create one-hot-encoded tensors of our &quot;total_lines&quot; column</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>train_total_lines_one_hot <span class="op">=</span> tf.one_hot(train_df[<span class="st">&quot;total_lines&quot;</span>].to_numpy(), depth<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a>val_total_lines_one_hot <span class="op">=</span> tf.one_hot(val_df[<span class="st">&quot;total_lines&quot;</span>].to_numpy(), depth<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb177-4"><a href="#cb177-4" aria-hidden="true" tabindex="-1"></a>test_total_lines_one_hot <span class="op">=</span> tf.one_hot(test_df[<span class="st">&quot;total_lines&quot;</span>].to_numpy(), depth<span class="op">=</span><span class="dv">20</span>)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="98"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="EiJC28WGLr0u"
  data-outputId="4cd44882-bed7-4c1c-fc6a-6f16469d5cda"
>
  <div class="sourceCode" id="cb178">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check shape and samples of total lines one-hot tensor</span></span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>train_total_lines_one_hot.shape, train_total_lines_one_hot[:<span class="dv">10</span>]</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="98">
    <pre><code>(TensorShape([180040, 20]),
 &lt;tf.Tensor: shape=(10, 20), dtype=float32, numpy=
 array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0., 0., 0.]], dtype=float32)&gt;)</code></pre>
  </div>
</div>
<section id="evaluation" class="cell-markdown" id="5bPKm0GZAFwi">
  <h2>Evaluation</h2>
</section>
<section
  id="building-a-tribrid-embedding-model"
  class="cell-markdown"
  id="xI8VBx0GC7-M"
>
  <h3>Building a tribrid embedding model</h3>
</section>
<div class="cell-markdown" id="vSAWqtYTDARW">
  <p>Woohoo! Positional embedding tensors ready.</p>
  <p>
    It's time to build the biggest model we've built yet. One which incorporates
    token embeddings, character embeddings and our newly crafted positional
    embeddings.
  </p>
  <p>
    We'll be venturing into uncovered territory but there will be nothing here
    you haven't practiced before.
  </p>
  <p>More specifically we're going to go through the following steps:</p>
  <ol>
    <li>Create a token-level model (similar to model_1)</li>
    <li>
      Create a character-level model (similar to model_3 with a slight
      modification to reflect the paper)
    </li>
    <li>
      Create a "line_number" model (takes in one-hot-encoded "line_number"
      tensor and passes it through a non-linear layer)
    </li>
    <li>
      Create a "total_lines" model (takes in one-hot-encoded "total_lines"
      tensor and passes it through a non-linear layer)
    </li>
    <li>
      Combine (using layers.Concatenate) the outputs of 1 and 2 into a
      token-character-hybrid embedding and pass it series of output to Figure 1
      and section 4.2 of [*Neural Networks for Joint Sentence Classification
    </li>
  </ol>
</div>
<div class="cell-code" data-execution_count="99" id="Il-s4SBZC_29">
  <div class="sourceCode" id="cb180">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Token inputs</span></span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>token_inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>[], dtype<span class="op">=</span><span class="st">&quot;string&quot;</span>, name<span class="op">=</span><span class="st">&quot;token_inputs&quot;</span>)</span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>token_embeddings <span class="op">=</span> tf_hub_embedding_layer(token_inputs)</span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>token_outputs <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(token_embeddings)</span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a>token_model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>token_inputs,</span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a>                             outputs<span class="op">=</span>token_outputs)</span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Char inputs</span></span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a>char_inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span><span class="st">&quot;string&quot;</span>, name<span class="op">=</span><span class="st">&quot;char_inputs&quot;</span>)</span>
<span id="cb180-10"><a href="#cb180-10" aria-hidden="true" tabindex="-1"></a>char_vectors <span class="op">=</span> char_vectorizer(char_inputs)</span>
<span id="cb180-11"><a href="#cb180-11" aria-hidden="true" tabindex="-1"></a>char_embeddings <span class="op">=</span> char_embed(char_vectors)</span>
<span id="cb180-12"><a href="#cb180-12" aria-hidden="true" tabindex="-1"></a>char_bi_lstm <span class="op">=</span> layers.Bidirectional(layers.LSTM(<span class="dv">32</span>))(char_embeddings)</span>
<span id="cb180-13"><a href="#cb180-13" aria-hidden="true" tabindex="-1"></a>char_model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>char_inputs,</span>
<span id="cb180-14"><a href="#cb180-14" aria-hidden="true" tabindex="-1"></a>                            outputs<span class="op">=</span>char_bi_lstm)</span>
<span id="cb180-15"><a href="#cb180-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-16"><a href="#cb180-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Line numbers inputs</span></span>
<span id="cb180-17"><a href="#cb180-17" aria-hidden="true" tabindex="-1"></a>line_number_inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">15</span>,), dtype<span class="op">=</span>tf.int32, name<span class="op">=</span><span class="st">&quot;line_number_input&quot;</span>)</span>
<span id="cb180-18"><a href="#cb180-18" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(line_number_inputs)</span>
<span id="cb180-19"><a href="#cb180-19" aria-hidden="true" tabindex="-1"></a>line_number_model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>line_number_inputs,</span>
<span id="cb180-20"><a href="#cb180-20" aria-hidden="true" tabindex="-1"></a>                                   outputs<span class="op">=</span>x)</span>
<span id="cb180-21"><a href="#cb180-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-22"><a href="#cb180-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Total lines inputs</span></span>
<span id="cb180-23"><a href="#cb180-23" aria-hidden="true" tabindex="-1"></a>total_lines_inputs <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="dv">20</span>,), dtype<span class="op">=</span>tf.int32, name<span class="op">=</span><span class="st">&quot;total_lines_input&quot;</span>)</span>
<span id="cb180-24"><a href="#cb180-24" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(total_lines_inputs)</span>
<span id="cb180-25"><a href="#cb180-25" aria-hidden="true" tabindex="-1"></a>total_line_model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>total_lines_inputs,</span>
<span id="cb180-26"><a href="#cb180-26" aria-hidden="true" tabindex="-1"></a>                                  outputs<span class="op">=</span>y)</span>
<span id="cb180-27"><a href="#cb180-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-28"><a href="#cb180-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Combine token and char embeddings into a hybrid embedding</span></span>
<span id="cb180-29"><a href="#cb180-29" aria-hidden="true" tabindex="-1"></a>combined_embeddings <span class="op">=</span> layers.Concatenate(name<span class="op">=</span><span class="st">&quot;token_char_hybrid_embedding&quot;</span>)([token_model.output,</span>
<span id="cb180-30"><a href="#cb180-30" aria-hidden="true" tabindex="-1"></a>                                                                              char_model.output])</span>
<span id="cb180-31"><a href="#cb180-31" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(combined_embeddings)</span>
<span id="cb180-32"><a href="#cb180-32" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> layers.Dropout(<span class="fl">0.5</span>)(z)</span>
<span id="cb180-33"><a href="#cb180-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-34"><a href="#cb180-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding</span></span>
<span id="cb180-35"><a href="#cb180-35" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> layers.Concatenate(name<span class="op">=</span><span class="st">&quot;token_char_positional_embedding&quot;</span>)([line_number_model.output,</span>
<span id="cb180-36"><a href="#cb180-36" aria-hidden="true" tabindex="-1"></a>                                                                total_line_model.output,</span>
<span id="cb180-37"><a href="#cb180-37" aria-hidden="true" tabindex="-1"></a>                                                                z])</span>
<span id="cb180-38"><a href="#cb180-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-39"><a href="#cb180-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Create output layer</span></span>
<span id="cb180-40"><a href="#cb180-40" aria-hidden="true" tabindex="-1"></a>output_layer <span class="op">=</span> layers.Dense(<span class="dv">5</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>, name<span class="op">=</span><span class="st">&quot;output_layer&quot;</span>)(z)</span>
<span id="cb180-41"><a href="#cb180-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-42"><a href="#cb180-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Put together model</span></span>
<span id="cb180-43"><a href="#cb180-43" aria-hidden="true" tabindex="-1"></a>model_5 <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[line_number_model.<span class="bu">input</span>,</span>
<span id="cb180-44"><a href="#cb180-44" aria-hidden="true" tabindex="-1"></a>                                 total_line_model.<span class="bu">input</span>,</span>
<span id="cb180-45"><a href="#cb180-45" aria-hidden="true" tabindex="-1"></a>                                 token_model.<span class="bu">input</span>,</span>
<span id="cb180-46"><a href="#cb180-46" aria-hidden="true" tabindex="-1"></a>                                 char_model.<span class="bu">input</span>],</span>
<span id="cb180-47"><a href="#cb180-47" aria-hidden="true" tabindex="-1"></a>                         outputs<span class="op">=</span>output_layer)</span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="100"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="SETu6E08C7TD"
  data-outputId="5f0a39ef-d11d-43eb-b338-9123e6e79f42"
>
  <div class="sourceCode" id="cb181">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a summary of our token, char and positional embedding model</span></span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>model_5.summary()</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Model: &quot;model_8&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 char_inputs (InputLayer)       [(None, 1)]          0           []                               
                                                                                                  
 token_inputs (InputLayer)      [(None,)]            0           []                               
                                                                                                  
 char_vectorizer (TextVectoriza  (None, 290)         0           [&#39;char_inputs[0][0]&#39;]            
 tion)                                                                                            
                                                                                                  
 universal_sentence_encoder (Ke  (None, 512)         256797824   [&#39;token_inputs[0][0]&#39;]           
 rasLayer)                                                                                        
                                                                                                  
 char_embed (Embedding)         (None, 290, 25)      1750        [&#39;char_vectorizer[2][0]&#39;]        
                                                                                                  
 dense_7 (Dense)                (None, 128)          65664       [&#39;universal_sentence_encoder[2][0
                                                                 ]&#39;]                              
                                                                                                  
 bidirectional_1 (Bidirectional  (None, 64)          14848       [&#39;char_embed[2][0]&#39;]             
 )                                                                                                
                                                                                                  
 token_char_hybrid_embedding (C  (None, 192)         0           [&#39;dense_7[0][0]&#39;,                
 oncatenate)                                                      &#39;bidirectional_1[0][0]&#39;]        
                                                                                                  
 line_number_input (InputLayer)  [(None, 15)]        0           []                               
                                                                                                  
 total_lines_input (InputLayer)  [(None, 20)]        0           []                               
                                                                                                  
 dense_10 (Dense)               (None, 256)          49408       [&#39;token_char_hybrid_embedding[0][
                                                                 0]&#39;]                             
                                                                                                  
 dense_8 (Dense)                (None, 32)           512         [&#39;line_number_input[0][0]&#39;]      
                                                                                                  
 dense_9 (Dense)                (None, 32)           672         [&#39;total_lines_input[0][0]&#39;]      
                                                                                                  
 dropout_2 (Dropout)            (None, 256)          0           [&#39;dense_10[0][0]&#39;]               
                                                                                                  
 token_char_positional_embeddin  (None, 320)         0           [&#39;dense_8[0][0]&#39;,                
 g (Concatenate)                                                  &#39;dense_9[0][0]&#39;,                
                                                                  &#39;dropout_2[0][0]&#39;]              
                                                                                                  
 output_layer (Dense)           (None, 5)            1605        [&#39;token_char_positional_embedding
                                                                 [0][0]&#39;]                         
                                                                                                  
==================================================================================================
Total params: 256,932,283
Trainable params: 134,459
Non-trainable params: 256,797,824
__________________________________________________________________________________________________
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="101"
  data-colab='{"base_uri":"https://localhost:8080/","height":856}'
  id="XQQEi7YGEMtr"
  data-outputId="403939aa-40aa-42df-d44d-222e64054e36"
>
  <div class="sourceCode" id="cb183">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the token, char, positional embedding model</span></span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> plot_model</span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>plot_model(model_5)</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="101">
    <p>
      <img
        src="{% static 'img\skimlit\457a3f2ec38d154284bf320bab2c1c3ba883fce1.png' %}"
      />
    </p>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="102"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="qflXYWdpEQYb"
  data-outputId="fa0da4f1-4174-44b0-b25d-8ade6cd71f55"
>
  <div class="sourceCode" id="cb184">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check which layers of our model are trainable or not</span></span>
<span id="cb184-2"><a href="#cb184-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> model_5.layers:</span>
<span id="cb184-3"><a href="#cb184-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(layer, layer.trainable)</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>&lt;keras.engine.input_layer.InputLayer object at 0x7f824de30a90&gt; True
&lt;keras.engine.input_layer.InputLayer object at 0x7f824de30160&gt; True
&lt;keras.layers.preprocessing.text_vectorization.TextVectorization object at 0x7f81fc4b5ff0&gt; True
&lt;tensorflow_hub.keras_layer.KerasLayer object at 0x7f825475d300&gt; False
&lt;keras.layers.core.embedding.Embedding object at 0x7f8244b33220&gt; True
&lt;keras.layers.core.dense.Dense object at 0x7f824de31ff0&gt; True
&lt;keras.layers.rnn.bidirectional.Bidirectional object at 0x7f824deb8520&gt; True
&lt;keras.layers.merging.concatenate.Concatenate object at 0x7f824dd7d390&gt; True
&lt;keras.engine.input_layer.InputLayer object at 0x7f824ddcdd20&gt; True
&lt;keras.engine.input_layer.InputLayer object at 0x7f824dec8be0&gt; True
&lt;keras.layers.core.dense.Dense object at 0x7f824ddf1660&gt; True
&lt;keras.layers.core.dense.Dense object at 0x7f824dfc3bb0&gt; True
&lt;keras.layers.core.dense.Dense object at 0x7f824de96d70&gt; True
&lt;keras.layers.regularization.dropout.Dropout object at 0x7f824deba140&gt; True
&lt;keras.layers.merging.concatenate.Concatenate object at 0x7f824ddf2410&gt; True
&lt;keras.layers.core.dense.Dense object at 0x7f824ddf1d50&gt; True
</code></pre>
  </div>
</div>
<div class="cell-code" data-execution_count="103" id="YI-QnNZZERUW">
  <div class="sourceCode" id="cb186">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile token, char, positional embedding model</span></span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a>model_5.<span class="bu">compile</span>(loss<span class="op">=</span>tf.keras.losses.CategoricalCrossentropy(label_smoothing<span class="op">=</span><span class="fl">0.2</span>), <span class="co"># add label smoothing (examples which are really confident get smoothed a little)</span></span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>                optimizer<span class="op">=</span>tf.keras.optimizers.Adam(),</span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span></code></pre>
  </div>
</div>
<section
  id="create-tribrid-embedding-datasets-and-fit-tribrid-model"
  class="cell-markdown"
  id="GFjB2ZDoETpF"
>
  <h3>Create tribrid embedding datasets and fit tribrid model</h3>
</section>
<div class="cell-markdown" id="cGxMaJGLEWam">
  <p>This time our model requires four feature inputs:</p>
  <ol>
    <li>Train line numbers one-hot tensor (train_line_numbers_one_hot)</li>
    <li>Train total lines one-hot tensor (train_total_lines_one_hot)</li>
    <li>Token-level sequences tensor (train_sentences)</li>
    <li>Char-level sequences tensor (train_chars)</li>
  </ol>
</div>
<div
  class="cell-code"
  data-execution_count="104"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="RL-2TZciEf7b"
  data-outputId="c5a73ca9-d1e8-4df8-8593-99eeb9cf1f98"
>
  <div class="sourceCode" id="cb187">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training and validation datasets (all four kinds of inputs)</span></span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a>train_pos_char_token_data <span class="op">=</span> tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, <span class="co"># line numbers</span></span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a>                                                                train_total_lines_one_hot, <span class="co"># total lines</span></span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a>                                                                train_sentences, <span class="co"># train tokens</span></span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a>                                                                train_chars)) <span class="co"># train chars</span></span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a>train_pos_char_token_labels <span class="op">=</span> tf.data.Dataset.from_tensor_slices(train_labels_one_hot) <span class="co"># train labels</span></span>
<span id="cb187-7"><a href="#cb187-7" aria-hidden="true" tabindex="-1"></a>train_pos_char_token_dataset <span class="op">=</span> tf.data.Dataset.<span class="bu">zip</span>((train_pos_char_token_data, train_pos_char_token_labels)) <span class="co"># combine data and labels</span></span>
<span id="cb187-8"><a href="#cb187-8" aria-hidden="true" tabindex="-1"></a>train_pos_char_token_dataset <span class="op">=</span> train_pos_char_token_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE) <span class="co"># turn into batches and prefetch appropriately</span></span>
<span id="cb187-9"><a href="#cb187-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-10"><a href="#cb187-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Validation dataset</span></span>
<span id="cb187-11"><a href="#cb187-11" aria-hidden="true" tabindex="-1"></a>val_pos_char_token_data <span class="op">=</span> tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,</span>
<span id="cb187-12"><a href="#cb187-12" aria-hidden="true" tabindex="-1"></a>                                                              val_total_lines_one_hot,</span>
<span id="cb187-13"><a href="#cb187-13" aria-hidden="true" tabindex="-1"></a>                                                              val_sentences,</span>
<span id="cb187-14"><a href="#cb187-14" aria-hidden="true" tabindex="-1"></a>                                                              val_chars))</span>
<span id="cb187-15"><a href="#cb187-15" aria-hidden="true" tabindex="-1"></a>val_pos_char_token_labels <span class="op">=</span> tf.data.Dataset.from_tensor_slices(val_labels_one_hot)</span>
<span id="cb187-16"><a href="#cb187-16" aria-hidden="true" tabindex="-1"></a>val_pos_char_token_dataset <span class="op">=</span> tf.data.Dataset.<span class="bu">zip</span>((val_pos_char_token_data, val_pos_char_token_labels))</span>
<span id="cb187-17"><a href="#cb187-17" aria-hidden="true" tabindex="-1"></a>val_pos_char_token_dataset <span class="op">=</span> val_pos_char_token_dataset.batch(<span class="dv">32</span>).prefetch(tf.data.AUTOTUNE) <span class="co"># turn into batches and prefetch appropriately</span></span>
<span id="cb187-18"><a href="#cb187-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-19"><a href="#cb187-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Check input shapes</span></span>
<span id="cb187-20"><a href="#cb187-20" aria-hidden="true" tabindex="-1"></a>train_pos_char_token_dataset, val_pos_char_token_dataset</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="104">
    <pre><code>(&lt;_PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))&gt;,
 &lt;_PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))&gt;)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="105"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="KsJ4VwETEhle"
  data-outputId="8b639edb-1b54-48e1-c8c1-dba12cbde9d6"
>
  <div class="sourceCode" id="cb189">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the token, char and positional embedding model</span></span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>history_model_5 <span class="op">=</span> model_5.fit(train_pos_char_token_dataset,</span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>                              steps_per_epoch<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(train_pos_char_token_dataset)),</span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>                              epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb189-5"><a href="#cb189-5" aria-hidden="true" tabindex="-1"></a>                              validation_data<span class="op">=</span>val_pos_char_token_dataset,</span>
<span id="cb189-6"><a href="#cb189-6" aria-hidden="true" tabindex="-1"></a>                              validation_steps<span class="op">=</span><span class="bu">int</span>(<span class="fl">0.1</span> <span class="op">*</span> <span class="bu">len</span>(val_pos_char_token_dataset)))</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>Epoch 1/3
562/562 [==============================] - 27s 37ms/step - loss: 1.1004 - accuracy: 0.7207 - val_loss: 0.9884 - val_accuracy: 0.8022
Epoch 2/3
562/562 [==============================] - 20s 35ms/step - loss: 0.9697 - accuracy: 0.8157 - val_loss: 0.9522 - val_accuracy: 0.8314
Epoch 3/3
562/562 [==============================] - 19s 34ms/step - loss: 0.9518 - accuracy: 0.8221 - val_loss: 0.9397 - val_accuracy: 0.8318
</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="106"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="m3HgnqYcEjdk"
  data-outputId="7beddf23-8dc3-48d3-8b76-d4ce4bf435ea"
>
  <div class="sourceCode" id="cb191">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions with token-char-positional hybrid model</span></span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>model_5_pred_probs <span class="op">=</span> model_5.predict(val_pos_char_token_dataset, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb191-3"><a href="#cb191-3" aria-hidden="true" tabindex="-1"></a>model_5_pred_probs</span></code></pre>
  </div>
  <div class="output stream stdout">
    <pre><code>945/945 [==============================] - 20s 19ms/step
</code></pre>
  </div>
  <div class="output execute_result" data-execution_count="106">
    <pre><code>array([[0.495109  , 0.09515629, 0.01086212, 0.38178325, 0.01708935],
       [0.53432745, 0.09549283, 0.05689869, 0.30267295, 0.01060806],
       [0.26504838, 0.08829384, 0.12924226, 0.44840795, 0.06900754],
       ...,
       [0.04196859, 0.09466297, 0.03414337, 0.03458292, 0.79464215],
       [0.02960509, 0.32149023, 0.07062276, 0.02571427, 0.55256766],
       [0.15812601, 0.56352526, 0.13694899, 0.03995618, 0.10144349]],
      dtype=float32)</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="107"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="Vtxfcm9AElSH"
  data-outputId="8f7a0026-88d2-4a91-8bf9-6270e653d75c"
>
  <div class="sourceCode" id="cb194">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn prediction probabilities into prediction classes</span></span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>model_5_preds <span class="op">=</span> tf.argmax(model_5_pred_probs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb194-3"><a href="#cb194-3" aria-hidden="true" tabindex="-1"></a>model_5_preds</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="107">
    <pre><code>&lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])&gt;</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="108"
  data-colab='{"base_uri":"https://localhost:8080/"}'
  id="T8ekEoY9Emzi"
  data-outputId="79cecee9-5160-4295-9971-0d5237810705"
>
  <div class="sourceCode" id="cb196">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate results of token-char-positional hybrid model</span></span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a>model_5_results <span class="op">=</span> calculate_results(y_true<span class="op">=</span>val_labels_encoded,</span>
<span id="cb196-3"><a href="#cb196-3" aria-hidden="true" tabindex="-1"></a>                                    y_pred<span class="op">=</span>model_5_preds)</span>
<span id="cb196-4"><a href="#cb196-4" aria-hidden="true" tabindex="-1"></a>model_5_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="108">
    <pre><code>{&#39;accuracy&#39;: 83.20534886799948,
 &#39;precision&#39;: 0.8309342723482521,
 &#39;recall&#39;: 0.8320534886799947,
 &#39;f1&#39;: 0.8313180995870428}</code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="109"
  data-colab='{"base_uri":"https://localhost:8080/","height":238}'
  id="I7I6O4TYFDC-"
  data-outputId="1328dc2b-be56-4f95-f9a6-c3760009f6df"
>
  <div class="sourceCode" id="cb198">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine model results into a DataFrame</span></span>
<span id="cb198-2"><a href="#cb198-2" aria-hidden="true" tabindex="-1"></a>all_model_results <span class="op">=</span> pd.DataFrame({<span class="st">&quot;Model 0 : baseline&quot;</span>: baseline_results,</span>
<span id="cb198-3"><a href="#cb198-3" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;Model 1 : custom_token_embed_conv1d&quot;</span>: model_1_results,</span>
<span id="cb198-4"><a href="#cb198-4" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;Model 2 : pretrained_token_embed&quot;</span>: model_2_results,</span>
<span id="cb198-5"><a href="#cb198-5" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;Model 3 : custom_char_embed_conv1d&quot;</span>: model_3_results,</span>
<span id="cb198-6"><a href="#cb198-6" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;Model 4 : hybrid_char_token_embed&quot;</span>: model_4_results,</span>
<span id="cb198-7"><a href="#cb198-7" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;Model 5 : tribrid_pos_char_token_embed&quot;</span>: model_5_results})</span>
<span id="cb198-8"><a href="#cb198-8" aria-hidden="true" tabindex="-1"></a>all_model_results <span class="op">=</span> all_model_results.transpose()</span>
<span id="cb198-9"><a href="#cb198-9" aria-hidden="true" tabindex="-1"></a>all_model_results</span></code></pre>
  </div>
  <div class="output execute_result" data-execution_count="109">
    <div id="df-ff48529c-6cd6-44f4-9af9-98813d3d4038">
      <div class="colab-df-container">
        <div>
          <style scoped>
            .dataframe tbody tr th:only-of-type {
              vertical-align: middle;
            }

            .dataframe tbody tr th {
              vertical-align: top;
            }

            .dataframe thead th {
              text-align: right;
            }
          </style>
          <table border="1" class="dataframe">
            <thead>
              <tr style="text-align: right">
                <th></th>
                <th>accuracy</th>
                <th>precision</th>
                <th>recall</th>
                <th>f1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th>Model 0 : baseline</th>
                <td>72.183238</td>
                <td>0.718647</td>
                <td>0.721832</td>
                <td>0.698925</td>
              </tr>
              <tr>
                <th>Model 1 : custom_token_embed_conv1d</th>
                <td>78.439031</td>
                <td>0.780880</td>
                <td>0.784390</td>
                <td>0.782098</td>
              </tr>
              <tr>
                <th>Model 2 : pretrained_token_embed</th>
                <td>71.273004</td>
                <td>0.712964</td>
                <td>0.712730</td>
                <td>0.709805</td>
              </tr>
              <tr>
                <th>Model 3 : custom_char_embed_conv1d</th>
                <td>65.212498</td>
                <td>0.645840</td>
                <td>0.652125</td>
                <td>0.642141</td>
              </tr>
              <tr>
                <th>Model 4 : hybrid_char_token_embed</th>
                <td>73.417847</td>
                <td>0.735862</td>
                <td>0.734178</td>
                <td>0.732251</td>
              </tr>
              <tr>
                <th>Model 5 : tribrid_pos_char_token_embed</th>
                <td>83.205349</td>
                <td>0.830934</td>
                <td>0.832053</td>
                <td>0.831318</td>
              </tr>
            </tbody>
          </table>
        </div>
        <button
          class="colab-df-convert"
          onclick="convertToInteractive('df-ff48529c-6cd6-44f4-9af9-98813d3d4038')"
          title="Convert this dataframe to an interactive table."
          style="display: none"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            height="24px"
            viewBox="0 0 24 24"
            width="24px"
          >
            <path d="M0 0h24v24H0V0z" fill="none" />
            <path
              d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"
            />
            <path
              d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"
            />
          </svg>
        </button>

        <div id="df-11ba0227-e90b-41a3-a669-655264b32824">
          <button
            class="colab-df-quickchart"
            onclick="quickchart('df-11ba0227-e90b-41a3-a669-655264b32824')"
            title="Suggest charts."
            style="display: none"
          >
            <svg
              xmlns="http://www.w3.org/2000/svg"
              height="24px"
              viewBox="0 0 24 24"
              width="24px"
            >
              <g>
                <path
                  d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"
                />
              </g>
            </svg>
          </button>
        </div>

        <style>
          .colab-df-quickchart {
            background-color: #e8f0fe;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            fill: #1967d2;
            height: 32px;
            padding: 0 0 0 0;
            width: 32px;
          }

          .colab-df-quickchart:hover {
            background-color: #e2ebfa;
            box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3),
              0px 1px 3px 1px rgba(60, 64, 67, 0.15);
            fill: #174ea6;
          }

          [theme="dark"] .colab-df-quickchart {
            background-color: #3b4455;
            fill: #d2e3fc;
          }

          [theme="dark"] .colab-df-quickchart:hover {
            background-color: #434b5c;
            box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
            filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
            fill: #ffffff;
          }
        </style>

        <script>
          async function quickchart(key) {
            const containerElement = document.querySelector("#" + key);
            const charts = await google.colab.kernel.invokeFunction(
              "suggestCharts",
              [key],
              {}
            );
          }
        </script>

        <script>
          function displayQuickchartButton(domScope) {
            let quickchartButtonEl = domScope.querySelector(
              "#df-11ba0227-e90b-41a3-a669-655264b32824 button.colab-df-quickchart"
            );
            quickchartButtonEl.style.display = google.colab.kernel.accessAllowed
              ? "block"
              : "none";
          }

          displayQuickchartButton(document);
        </script>
        <style>
          .colab-df-container {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
          }

          .colab-df-convert {
            background-color: #e8f0fe;
            border: none;
            border-radius: 50%;
            cursor: pointer;
            display: none;
            fill: #1967d2;
            height: 32px;
            padding: 0 0 0 0;
            width: 32px;
          }

          .colab-df-convert:hover {
            background-color: #e2ebfa;
            box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3),
              0px 1px 3px 1px rgba(60, 64, 67, 0.15);
            fill: #174ea6;
          }

          [theme="dark"] .colab-df-convert {
            background-color: #3b4455;
            fill: #d2e3fc;
          }

          [theme="dark"] .colab-df-convert:hover {
            background-color: #434b5c;
            box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
            filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
            fill: #ffffff;
          }
        </style>

        <script>
          const buttonEl = document.querySelector(
            "#df-ff48529c-6cd6-44f4-9af9-98813d3d4038 button.colab-df-convert"
          );
          buttonEl.style.display = google.colab.kernel.accessAllowed
            ? "block"
            : "none";

          async function convertToInteractive(key) {
            const element = document.querySelector(
              "#df-ff48529c-6cd6-44f4-9af9-98813d3d4038"
            );
            const dataTable = await google.colab.kernel.invokeFunction(
              "convertToInteractive",
              [key],
              {}
            );
            if (!dataTable) return;

            const docLinkHtml =
              "Like what you see? Visit the " +
              '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>' +
              " to learn more about interactive tables.";
            element.innerHTML = "";
            dataTable["output_type"] = "display_data";
            await google.colab.output.renderOutput(dataTable, element);
            const docLink = document.createElement("div");
            docLink.innerHTML = docLinkHtml;
            element.appendChild(docLink);
          }
        </script>
      </div>
    </div>
  </div>
</div>
<div class="cell-code" data-execution_count="110" id="9r9NPoFxFibd">
  <div class="sourceCode" id="cb199">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reduce the accuracy to same scale as other metrics</span></span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>all_model_results[<span class="st">&quot;accuracy&quot;</span>] <span class="op">=</span> all_model_results[<span class="st">&quot;accuracy&quot;</span>]<span class="op">/</span><span class="dv">100</span></span></code></pre>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="111"
  data-colab='{"base_uri":"https://localhost:8080/","height":866}'
  id="T7Chnm4SFi7u"
  data-outputId="af537658-3caf-406b-ff8d-e936748bd769"
>
  <div class="sourceCode" id="cb200">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot and compare all of the model results</span></span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>all_model_results.plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>)).legend(bbox_to_anchor<span class="op">=</span>(<span class="fl">1.0</span>, <span class="fl">1.0</span>))<span class="op">;</span></span></code></pre>
  </div>
  <div class="output display_data">
    <p>
      <img
        src="{% static 'img\skimlit\47f96c6602afc4a57b50664047f0a084b3f48eb2.png' %}"
      />
    </p>
  </div>
</div>
<div
  class="cell-code"
  data-execution_count="112"
  data-colab='{"base_uri":"https://localhost:8080/","height":866}'
  id="NB7XZy9YFmCS"
  data-outputId="91554cdf-b4b7-4db5-d61c-d06f617fc46b"
>
  <div class="sourceCode" id="cb201">
    <div class="nomor-samping-cell">
      <h4>[1]</h4>
    </div>
    <pre
      class="sourceCode-python"
    ><code class="sourceCode-python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort model results by f1-score</span></span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a>all_model_results.sort_values(<span class="st">&quot;f1&quot;</span>, ascending<span class="op">=</span><span class="va">False</span>)[<span class="st">&quot;f1&quot;</span>].plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))<span class="op">;</span></span></code></pre>
  </div>
  <div class="output display_data">
    <p>
      <img
        src="{% static 'img\skimlit\e1484188009ed95e24eb4cfab7fcfed85764e53a.png' %}"
      />
    </p>
  </div>
</div>
{% endblock contents %}
